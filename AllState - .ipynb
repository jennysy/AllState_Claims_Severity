{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift =200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\hudsondata\\\\Machine Learning\\\\Kaggle\\AllState\\\\train.csv')\n",
    "test = pd.read_csv('C:\\\\hudsondata\\\\Machine Learning\\\\Kaggle\\AllState\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = [x for x in train.columns[1:-1] if 'cat' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "test['loss']=0\n",
    "train_test = pd.concat((train,test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_feats = train_test[numeric_feats].apply(lambda x: skew(x.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_feats = skewed_feats[abs(skewed_feats)>0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_feats= pd.DataFrame(skewed_feats).reset_index()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feats in skewed_feats:\n",
    "    train_test[feats] = train_test[feats] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feats in skewed_feats:\n",
    "    train_test[feats], lam = boxcox(train_test[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cats:\n",
    "    train_test[col] = pd.factorize(train_test[col], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test.loss = np.log(train_test.loss + shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test[numeric_feats] =ss.fit_transform(train_test[numeric_feats].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "test.drop('loss', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Median Loss:', 7.747411156506141)\n"
     ]
    }
   ],
   "source": [
    "print('Median Loss:', train.loss.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Loss:', 7.799837008871419)\n"
     ]
    }
   ],
   "source": [
    "print('Mean Loss:', train.loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.1,\n",
    "        'objective': 'reg:linear',\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 100,\n",
    "        'booster': 'gbtree',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_nrounds = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allpredictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x = preds-labels\n",
    "    grad = con*x / (np.abs(x)+con)\n",
    "    hess = con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
    "                                      np.exp(yhat)-shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110234</td>\n",
       "      <td>-0.871854</td>\n",
       "      <td>-0.989339</td>\n",
       "      <td>1.123537</td>\n",
       "      <td>1.647215</td>\n",
       "      <td>0.450314</td>\n",
       "      <td>0.563870</td>\n",
       "      <td>1.403248</td>\n",
       "      <td>1.007620</td>\n",
       "      <td>7.788701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135754</td>\n",
       "      <td>-0.112264</td>\n",
       "      <td>0.747696</td>\n",
       "      <td>-0.749060</td>\n",
       "      <td>-0.231931</td>\n",
       "      <td>-0.702751</td>\n",
       "      <td>-0.546698</td>\n",
       "      <td>0.683287</td>\n",
       "      <td>-0.839662</td>\n",
       "      <td>7.302227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.016579</td>\n",
       "      <td>-1.040409</td>\n",
       "      <td>-1.236757</td>\n",
       "      <td>-1.615922</td>\n",
       "      <td>-0.941361</td>\n",
       "      <td>-0.467237</td>\n",
       "      <td>-0.508036</td>\n",
       "      <td>-1.696411</td>\n",
       "      <td>1.208015</td>\n",
       "      <td>8.072495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125015</td>\n",
       "      <td>-0.429909</td>\n",
       "      <td>-0.867203</td>\n",
       "      <td>-1.013009</td>\n",
       "      <td>-0.200335</td>\n",
       "      <td>-0.761220</td>\n",
       "      <td>-0.796694</td>\n",
       "      <td>0.657995</td>\n",
       "      <td>0.591953</td>\n",
       "      <td>7.038652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.816004</td>\n",
       "      <td>-1.698643</td>\n",
       "      <td>-1.486329</td>\n",
       "      <td>-2.073037</td>\n",
       "      <td>-1.737857</td>\n",
       "      <td>-1.508394</td>\n",
       "      <td>-1.529282</td>\n",
       "      <td>-1.303842</td>\n",
       "      <td>-0.155206</td>\n",
       "      <td>7.994244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9    ...     \\\n",
       "0   1     0     1     0     1     0     0     0     0     1    ...      \n",
       "1   2     0     1     0     0     0     0     0     0     1    ...      \n",
       "2   5     0     1     0     0     1     0     0     0     1    ...      \n",
       "3  10     1     1     0     1     0     0     0     0     1    ...      \n",
       "4  11     0     1     0     1     0     0     0     0     1    ...      \n",
       "\n",
       "      cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "0  1.110234 -0.871854 -0.989339  1.123537  1.647215  0.450314  0.563870   \n",
       "1 -0.135754 -0.112264  0.747696 -0.749060 -0.231931 -0.702751 -0.546698   \n",
       "2 -1.016579 -1.040409 -1.236757 -1.615922 -0.941361 -0.467237 -0.508036   \n",
       "3 -0.125015 -0.429909 -0.867203 -1.013009 -0.200335 -0.761220 -0.796694   \n",
       "4 -1.816004 -1.698643 -1.486329 -2.073037 -1.737857 -1.508394 -1.529282   \n",
       "\n",
       "     cont13    cont14      loss  \n",
       "0  1.403248  1.007620  7.788701  \n",
       "1  0.683287 -0.839662  7.302227  \n",
       "2 -1.696411  1.208015  8.072495  \n",
       "3  0.657995  0.591953  7.038652  \n",
       "4 -1.303842 -0.155206  7.994244  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train,y_val = train_test_split(train.iloc[:,1:-1], train.iloc[:,-1], test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfolds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mae:3188.223145\teval-mae:3182.067871\n",
      "[1]\ttrain-mae:3076.520508\teval-mae:3070.118896\n",
      "[2]\ttrain-mae:2926.947998\teval-mae:2920.026855\n",
      "[3]\ttrain-mae:2760.968994\teval-mae:2753.555420\n",
      "[4]\ttrain-mae:2589.693848\teval-mae:2581.534668\n",
      "[5]\ttrain-mae:2424.083008\teval-mae:2415.276611\n",
      "[6]\ttrain-mae:2268.182861\teval-mae:2258.820557\n",
      "[7]\ttrain-mae:2124.280762\teval-mae:2114.700684\n",
      "[8]\ttrain-mae:1994.265869\teval-mae:1985.179443\n",
      "[9]\ttrain-mae:1877.138184\teval-mae:1868.383179\n",
      "[10]\ttrain-mae:1773.399658\teval-mae:1765.806763\n",
      "[11]\ttrain-mae:1682.202759\teval-mae:1676.558350\n",
      "[12]\ttrain-mae:1603.258545\teval-mae:1599.835449\n",
      "[13]\ttrain-mae:1534.758179\teval-mae:1534.042969\n",
      "[14]\ttrain-mae:1476.227295\teval-mae:1478.187744\n",
      "[15]\ttrain-mae:1425.649902\teval-mae:1429.964600\n",
      "[16]\ttrain-mae:1382.530640\teval-mae:1388.938232\n",
      "[17]\ttrain-mae:1345.548218\teval-mae:1354.162476\n",
      "[18]\ttrain-mae:1314.215698\teval-mae:1325.057373\n",
      "[19]\ttrain-mae:1287.316772\teval-mae:1300.125366\n",
      "[20]\ttrain-mae:1264.552979\teval-mae:1279.314941\n",
      "[21]\ttrain-mae:1245.569702\teval-mae:1262.178833\n",
      "[22]\ttrain-mae:1229.557617\teval-mae:1248.182007\n",
      "[23]\ttrain-mae:1215.432495\teval-mae:1236.416016\n",
      "[24]\ttrain-mae:1203.731934\teval-mae:1226.545044\n",
      "[25]\ttrain-mae:1193.692871\teval-mae:1218.244385\n",
      "[26]\ttrain-mae:1184.914795\teval-mae:1211.294189\n",
      "[27]\ttrain-mae:1177.888062\teval-mae:1205.827271\n",
      "[28]\ttrain-mae:1171.167603\teval-mae:1200.539185\n",
      "[29]\ttrain-mae:1165.122192\teval-mae:1196.355469\n",
      "[30]\ttrain-mae:1159.918701\teval-mae:1192.698120\n",
      "[31]\ttrain-mae:1155.318604\teval-mae:1189.404053\n",
      "[32]\ttrain-mae:1151.037476\teval-mae:1186.452881\n",
      "[33]\ttrain-mae:1147.727905\teval-mae:1184.162109\n",
      "[34]\ttrain-mae:1143.390625\teval-mae:1181.167847\n",
      "[35]\ttrain-mae:1140.331909\teval-mae:1179.505981\n",
      "[36]\ttrain-mae:1137.519165\teval-mae:1177.904785\n",
      "[37]\ttrain-mae:1134.505981\teval-mae:1176.229614\n",
      "[38]\ttrain-mae:1132.417725\teval-mae:1175.158569\n",
      "[39]\ttrain-mae:1130.221191\teval-mae:1174.162598\n",
      "[40]\ttrain-mae:1128.500000\teval-mae:1173.272583\n",
      "[41]\ttrain-mae:1126.307373\teval-mae:1172.122803\n",
      "[42]\ttrain-mae:1124.576660\teval-mae:1171.291504\n",
      "[43]\ttrain-mae:1122.454956\teval-mae:1170.333252\n",
      "[44]\ttrain-mae:1121.368652\teval-mae:1169.627808\n",
      "[45]\ttrain-mae:1120.088989\teval-mae:1168.983765\n",
      "[46]\ttrain-mae:1118.355225\teval-mae:1168.122925\n",
      "[47]\ttrain-mae:1116.584106\teval-mae:1167.257935\n",
      "[48]\ttrain-mae:1114.943604\teval-mae:1166.757080\n",
      "[49]\ttrain-mae:1113.243042\teval-mae:1166.184326\n",
      "[50]\ttrain-mae:1112.527832\teval-mae:1165.732544\n",
      "[51]\ttrain-mae:1110.937744\teval-mae:1164.860596\n",
      "[52]\ttrain-mae:1109.271362\teval-mae:1164.032471\n",
      "[53]\ttrain-mae:1108.015381\teval-mae:1163.530273\n",
      "[54]\ttrain-mae:1106.670654\teval-mae:1163.139404\n",
      "[55]\ttrain-mae:1105.459717\teval-mae:1162.839600\n",
      "[56]\ttrain-mae:1104.373047\teval-mae:1162.353027\n",
      "[57]\ttrain-mae:1103.340332\teval-mae:1161.991455\n",
      "[58]\ttrain-mae:1102.718750\teval-mae:1161.837769\n",
      "[59]\ttrain-mae:1101.966187\teval-mae:1161.647095\n",
      "[60]\ttrain-mae:1101.116821\teval-mae:1161.283936\n",
      "[61]\ttrain-mae:1099.841431\teval-mae:1161.135254\n",
      "[62]\ttrain-mae:1097.987671\teval-mae:1160.746338\n",
      "[63]\ttrain-mae:1096.691284\teval-mae:1160.493042\n",
      "[64]\ttrain-mae:1096.313354\teval-mae:1160.358276\n",
      "[65]\ttrain-mae:1095.198242\teval-mae:1160.270386\n",
      "[66]\ttrain-mae:1094.631104\teval-mae:1160.104126\n",
      "[67]\ttrain-mae:1093.700684\teval-mae:1159.842529\n",
      "[68]\ttrain-mae:1092.847046\teval-mae:1159.577393\n",
      "[69]\ttrain-mae:1092.052734\teval-mae:1159.335205\n",
      "[70]\ttrain-mae:1091.199585\teval-mae:1159.087524\n",
      "[71]\ttrain-mae:1089.959839\teval-mae:1158.678101\n",
      "[72]\ttrain-mae:1089.237793\teval-mae:1158.504150\n",
      "[73]\ttrain-mae:1088.512695\teval-mae:1158.332397\n",
      "[74]\ttrain-mae:1088.032959\teval-mae:1158.254639\n",
      "[75]\ttrain-mae:1087.175171\teval-mae:1158.062622\n",
      "[76]\ttrain-mae:1086.709961\teval-mae:1157.899292\n",
      "[77]\ttrain-mae:1085.862305\teval-mae:1157.699097\n",
      "[78]\ttrain-mae:1085.102539\teval-mae:1157.521484\n",
      "[79]\ttrain-mae:1084.243774\teval-mae:1157.345947\n",
      "[80]\ttrain-mae:1083.366577\teval-mae:1157.354370\n",
      "[81]\ttrain-mae:1083.064087\teval-mae:1157.265869\n",
      "[82]\ttrain-mae:1082.396118\teval-mae:1157.301880\n",
      "[83]\ttrain-mae:1081.452271\teval-mae:1156.919556\n",
      "[84]\ttrain-mae:1080.818726\teval-mae:1156.805664\n",
      "[85]\ttrain-mae:1079.905396\teval-mae:1156.678467\n",
      "[86]\ttrain-mae:1079.680664\teval-mae:1156.666626\n",
      "[87]\ttrain-mae:1078.965210\teval-mae:1156.396973\n",
      "[88]\ttrain-mae:1078.389038\teval-mae:1156.213257\n",
      "[89]\ttrain-mae:1077.935425\teval-mae:1156.130981\n",
      "[90]\ttrain-mae:1076.834229\teval-mae:1156.003662\n",
      "[91]\ttrain-mae:1075.969604\teval-mae:1155.862793\n",
      "[92]\ttrain-mae:1075.550049\teval-mae:1155.752197\n",
      "[93]\ttrain-mae:1075.186401\teval-mae:1155.831299\n",
      "[94]\ttrain-mae:1074.589722\teval-mae:1155.878052\n",
      "[95]\ttrain-mae:1073.843994\teval-mae:1155.617065\n",
      "[96]\ttrain-mae:1072.583984\teval-mae:1155.563354\n",
      "[97]\ttrain-mae:1072.261475\teval-mae:1155.425293\n",
      "[98]\ttrain-mae:1071.151611\teval-mae:1155.223389\n",
      "[99]\ttrain-mae:1070.890015\teval-mae:1155.032227\n",
      "[100]\ttrain-mae:1070.586670\teval-mae:1155.053711\n",
      "[101]\ttrain-mae:1070.267334\teval-mae:1154.871338\n",
      "[102]\ttrain-mae:1070.027954\teval-mae:1154.838379\n",
      "[103]\ttrain-mae:1069.785522\teval-mae:1154.808105\n",
      "[104]\ttrain-mae:1069.141846\teval-mae:1154.737061\n",
      "[105]\ttrain-mae:1068.860352\teval-mae:1154.648804\n",
      "[106]\ttrain-mae:1068.331055\teval-mae:1154.520142\n",
      "[107]\ttrain-mae:1067.770752\teval-mae:1154.619141\n",
      "[108]\ttrain-mae:1066.902344\teval-mae:1154.550293\n",
      "[109]\ttrain-mae:1065.929688\teval-mae:1154.413940\n",
      "[110]\ttrain-mae:1065.096924\teval-mae:1154.274902\n",
      "[111]\ttrain-mae:1064.906372\teval-mae:1154.239868\n",
      "[112]\ttrain-mae:1064.452271\teval-mae:1154.174194\n",
      "[113]\ttrain-mae:1063.813965\teval-mae:1154.077271\n",
      "[114]\ttrain-mae:1063.351562\teval-mae:1154.002808\n",
      "[115]\ttrain-mae:1063.088989\teval-mae:1154.031494\n",
      "[116]\ttrain-mae:1062.554688\teval-mae:1153.912109\n",
      "[117]\ttrain-mae:1062.341187\teval-mae:1153.785522\n",
      "[118]\ttrain-mae:1061.697144\teval-mae:1153.594604\n",
      "[119]\ttrain-mae:1061.259033\teval-mae:1153.551025\n",
      "[120]\ttrain-mae:1060.870605\teval-mae:1153.522339\n",
      "[121]\ttrain-mae:1059.637329\teval-mae:1153.420166\n",
      "[122]\ttrain-mae:1059.109253\teval-mae:1153.466064\n",
      "[123]\ttrain-mae:1058.383667\teval-mae:1153.552246\n",
      "[124]\ttrain-mae:1057.754639\teval-mae:1153.398071\n",
      "[125]\ttrain-mae:1056.938354\teval-mae:1153.491577\n",
      "[126]\ttrain-mae:1056.602905\teval-mae:1153.396118\n",
      "[127]\ttrain-mae:1056.444458\teval-mae:1153.443970\n",
      "[128]\ttrain-mae:1055.563965\teval-mae:1153.411011\n",
      "[129]\ttrain-mae:1055.299805\teval-mae:1153.463379\n",
      "[130]\ttrain-mae:1054.854248\teval-mae:1153.306885\n",
      "[131]\ttrain-mae:1053.919312\teval-mae:1153.464966\n",
      "[132]\ttrain-mae:1053.107788\teval-mae:1153.462036\n",
      "[133]\ttrain-mae:1052.796631\teval-mae:1153.523926\n",
      "[134]\ttrain-mae:1052.232056\teval-mae:1153.379517\n",
      "[135]\ttrain-mae:1051.871216\teval-mae:1153.341064\n",
      "[136]\ttrain-mae:1051.462524\teval-mae:1153.208984\n",
      "[137]\ttrain-mae:1050.953735\teval-mae:1152.984619\n",
      "[138]\ttrain-mae:1050.503418\teval-mae:1152.904419\n",
      "[139]\ttrain-mae:1049.961304\teval-mae:1152.893188\n",
      "[140]\ttrain-mae:1049.370361\teval-mae:1152.856689\n",
      "[141]\ttrain-mae:1048.716187\teval-mae:1152.810913\n",
      "[142]\ttrain-mae:1048.373047\teval-mae:1152.834473\n",
      "[143]\ttrain-mae:1048.021729\teval-mae:1152.906738\n",
      "[144]\ttrain-mae:1047.609863\teval-mae:1152.786865\n",
      "[145]\ttrain-mae:1047.134399\teval-mae:1152.622803\n",
      "[146]\ttrain-mae:1046.862793\teval-mae:1152.652222\n",
      "[147]\ttrain-mae:1046.563477\teval-mae:1152.520020\n",
      "[148]\ttrain-mae:1045.997437\teval-mae:1152.539673\n",
      "[149]\ttrain-mae:1045.839966\teval-mae:1152.442993\n",
      "[150]\ttrain-mae:1045.264893\teval-mae:1152.454346\n",
      "[151]\ttrain-mae:1044.305054\teval-mae:1152.309204\n",
      "[152]\ttrain-mae:1043.955566\teval-mae:1152.278442\n",
      "[153]\ttrain-mae:1043.335938\teval-mae:1152.191406\n",
      "[154]\ttrain-mae:1042.860107\teval-mae:1152.099243\n",
      "[155]\ttrain-mae:1042.303711\teval-mae:1151.948853\n",
      "[156]\ttrain-mae:1041.816284\teval-mae:1151.764526\n",
      "[157]\ttrain-mae:1041.451172\teval-mae:1151.744385\n",
      "[158]\ttrain-mae:1040.989380\teval-mae:1151.795166\n",
      "[159]\ttrain-mae:1040.594482\teval-mae:1151.825928\n",
      "[160]\ttrain-mae:1040.295776\teval-mae:1151.761597\n",
      "[161]\ttrain-mae:1039.953735\teval-mae:1151.718262\n",
      "[162]\ttrain-mae:1039.649414\teval-mae:1151.621582\n",
      "[163]\ttrain-mae:1038.998657\teval-mae:1151.498779\n",
      "[164]\ttrain-mae:1038.150513\teval-mae:1151.575073\n",
      "[165]\ttrain-mae:1037.505981\teval-mae:1151.581543\n",
      "[166]\ttrain-mae:1036.258179\teval-mae:1151.479492\n",
      "[167]\ttrain-mae:1035.776001\teval-mae:1151.457886\n",
      "[168]\ttrain-mae:1035.216553\teval-mae:1151.396484\n",
      "[169]\ttrain-mae:1034.978027\teval-mae:1151.388916\n",
      "[170]\ttrain-mae:1034.471069\teval-mae:1151.459473\n",
      "[171]\ttrain-mae:1034.041138\teval-mae:1151.474121\n",
      "[172]\ttrain-mae:1033.599854\teval-mae:1151.580078\n",
      "[173]\ttrain-mae:1033.212891\teval-mae:1151.607300\n",
      "[174]\ttrain-mae:1032.786011\teval-mae:1151.546631\n",
      "[175]\ttrain-mae:1032.340210\teval-mae:1151.380371\n",
      "[176]\ttrain-mae:1031.800781\teval-mae:1151.299805\n",
      "[177]\ttrain-mae:1031.261963\teval-mae:1151.199463\n",
      "[178]\ttrain-mae:1030.929565\teval-mae:1151.223999\n",
      "[179]\ttrain-mae:1030.563354\teval-mae:1151.320679\n",
      "[180]\ttrain-mae:1029.649658\teval-mae:1151.377197\n",
      "[181]\ttrain-mae:1029.442993\teval-mae:1151.381714\n",
      "[182]\ttrain-mae:1028.897949\teval-mae:1151.285767\n",
      "[183]\ttrain-mae:1028.317261\teval-mae:1151.330688\n",
      "[184]\ttrain-mae:1027.853149\teval-mae:1151.481567\n",
      "[185]\ttrain-mae:1027.313721\teval-mae:1151.673828\n",
      "[186]\ttrain-mae:1026.903931\teval-mae:1151.689819\n",
      "[187]\ttrain-mae:1026.447021\teval-mae:1151.669067\n",
      "[188]\ttrain-mae:1026.072266\teval-mae:1151.561279\n",
      "[189]\ttrain-mae:1025.245850\teval-mae:1151.368042\n",
      "[190]\ttrain-mae:1025.087891\teval-mae:1151.376343\n",
      "[191]\ttrain-mae:1024.896118\teval-mae:1151.425293\n",
      "[192]\ttrain-mae:1024.466187\teval-mae:1151.567505\n",
      "[193]\ttrain-mae:1023.863342\teval-mae:1151.550781\n",
      "[194]\ttrain-mae:1023.544373\teval-mae:1151.550293\n",
      "[195]\ttrain-mae:1022.533203\teval-mae:1151.626343\n",
      "[196]\ttrain-mae:1022.116394\teval-mae:1151.659302\n",
      "[197]\ttrain-mae:1021.822632\teval-mae:1151.721436\n",
      "[198]\ttrain-mae:1021.663513\teval-mae:1151.707764\n",
      "[199]\ttrain-mae:1021.209900\teval-mae:1151.702759\n",
      "[200]\ttrain-mae:1020.845947\teval-mae:1151.697144\n",
      "[201]\ttrain-mae:1020.421448\teval-mae:1151.756104\n",
      "[202]\ttrain-mae:1020.123047\teval-mae:1151.721558\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-mae:1031.261963\teval-mae:1151.199463\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mae:3186.884277\teval-mae:3187.834229\n",
      "[1]\ttrain-mae:3075.301025\teval-mae:3076.104980\n",
      "[2]\ttrain-mae:2926.093750\teval-mae:2926.948975\n",
      "[3]\ttrain-mae:2759.505127\teval-mae:2760.211182\n",
      "[4]\ttrain-mae:2589.723877\teval-mae:2590.446533\n",
      "[5]\ttrain-mae:2424.015137\teval-mae:2424.974121\n",
      "[6]\ttrain-mae:2267.521240\teval-mae:2269.137207\n",
      "[7]\ttrain-mae:2122.578857\teval-mae:2124.713135\n",
      "[8]\ttrain-mae:1993.062134\teval-mae:1995.890015\n",
      "[9]\ttrain-mae:1876.710327\teval-mae:1880.375122\n",
      "[10]\ttrain-mae:1772.835693\teval-mae:1777.369019\n",
      "[11]\ttrain-mae:1682.082397\teval-mae:1687.388184\n",
      "[12]\ttrain-mae:1602.898315\teval-mae:1609.420898\n",
      "[13]\ttrain-mae:1534.809082\teval-mae:1542.701416\n",
      "[14]\ttrain-mae:1476.009766\teval-mae:1485.245483\n",
      "[15]\ttrain-mae:1425.547363\teval-mae:1436.509766\n",
      "[16]\ttrain-mae:1382.081909\teval-mae:1394.480347\n",
      "[17]\ttrain-mae:1345.945557\teval-mae:1359.574097\n",
      "[18]\ttrain-mae:1314.784180\teval-mae:1329.850220\n",
      "[19]\ttrain-mae:1288.410522\teval-mae:1304.747803\n",
      "[20]\ttrain-mae:1266.095825\teval-mae:1283.908203\n",
      "[21]\ttrain-mae:1246.181519\teval-mae:1265.103271\n",
      "[22]\ttrain-mae:1229.486572\teval-mae:1249.666016\n",
      "[23]\ttrain-mae:1215.384277\teval-mae:1236.620850\n",
      "[24]\ttrain-mae:1203.607788\teval-mae:1225.854980\n",
      "[25]\ttrain-mae:1193.344971\teval-mae:1216.556763\n",
      "[26]\ttrain-mae:1184.572388\teval-mae:1208.912476\n",
      "[27]\ttrain-mae:1177.088745\teval-mae:1202.251221\n",
      "[28]\ttrain-mae:1169.891846\teval-mae:1196.324951\n",
      "[29]\ttrain-mae:1163.800049\teval-mae:1191.449829\n",
      "[30]\ttrain-mae:1158.581909\teval-mae:1187.359497\n",
      "[31]\ttrain-mae:1154.044678\teval-mae:1183.698364\n",
      "[32]\ttrain-mae:1150.060547\teval-mae:1180.749634\n",
      "[33]\ttrain-mae:1146.864380\teval-mae:1178.387573\n",
      "[34]\ttrain-mae:1143.443970\teval-mae:1176.101807\n",
      "[35]\ttrain-mae:1141.122925\teval-mae:1174.298218\n",
      "[36]\ttrain-mae:1138.323120\teval-mae:1172.324951\n",
      "[37]\ttrain-mae:1135.925293\teval-mae:1170.742188\n",
      "[38]\ttrain-mae:1133.768433\teval-mae:1169.368286\n",
      "[39]\ttrain-mae:1131.416382\teval-mae:1168.272705\n",
      "[40]\ttrain-mae:1129.762451\teval-mae:1167.361572\n",
      "[41]\ttrain-mae:1127.449707\teval-mae:1166.071899\n",
      "[42]\ttrain-mae:1125.599731\teval-mae:1164.931519\n",
      "[43]\ttrain-mae:1123.484863\teval-mae:1164.002319\n",
      "[44]\ttrain-mae:1122.014160\teval-mae:1163.169678\n",
      "[45]\ttrain-mae:1120.382446\teval-mae:1162.492554\n",
      "[46]\ttrain-mae:1118.760254\teval-mae:1161.566040\n",
      "[47]\ttrain-mae:1116.841797\teval-mae:1160.784058\n",
      "[48]\ttrain-mae:1115.445923\teval-mae:1160.367310\n",
      "[49]\ttrain-mae:1114.384644\teval-mae:1159.975586\n",
      "[50]\ttrain-mae:1113.298218\teval-mae:1159.558228\n",
      "[51]\ttrain-mae:1111.007080\teval-mae:1158.474121\n",
      "[52]\ttrain-mae:1109.750366\teval-mae:1157.816528\n",
      "[53]\ttrain-mae:1108.650635\teval-mae:1157.155273\n",
      "[54]\ttrain-mae:1107.566528\teval-mae:1156.542480\n",
      "[55]\ttrain-mae:1105.875000\teval-mae:1156.023682\n",
      "[56]\ttrain-mae:1105.089722\teval-mae:1155.732788\n",
      "[57]\ttrain-mae:1103.641357\teval-mae:1155.532471\n",
      "[58]\ttrain-mae:1102.651611\teval-mae:1155.180298\n",
      "[59]\ttrain-mae:1102.000244\teval-mae:1155.040161\n",
      "[60]\ttrain-mae:1100.456421\teval-mae:1154.493896\n",
      "[61]\ttrain-mae:1099.419312\teval-mae:1154.331787\n",
      "[62]\ttrain-mae:1098.523438\teval-mae:1153.998657\n",
      "[63]\ttrain-mae:1097.636353\teval-mae:1153.845947\n",
      "[64]\ttrain-mae:1097.008057\teval-mae:1153.820801\n",
      "[65]\ttrain-mae:1096.292969\teval-mae:1153.797607\n",
      "[66]\ttrain-mae:1095.377441\teval-mae:1153.269165\n",
      "[67]\ttrain-mae:1094.139648\teval-mae:1153.133911\n",
      "[68]\ttrain-mae:1093.432861\teval-mae:1152.801758\n",
      "[69]\ttrain-mae:1092.572998\teval-mae:1152.786499\n",
      "[70]\ttrain-mae:1092.036743\teval-mae:1152.608765\n",
      "[71]\ttrain-mae:1091.291992\teval-mae:1152.438721\n",
      "[72]\ttrain-mae:1091.011841\teval-mae:1152.353149\n",
      "[73]\ttrain-mae:1090.500610\teval-mae:1152.301514\n",
      "[74]\ttrain-mae:1089.693359\teval-mae:1152.128784\n",
      "[75]\ttrain-mae:1088.808105\teval-mae:1152.006714\n",
      "[76]\ttrain-mae:1087.666626\teval-mae:1151.633789\n",
      "[77]\ttrain-mae:1087.059814\teval-mae:1151.566284\n",
      "[78]\ttrain-mae:1086.440918\teval-mae:1151.642578\n",
      "[79]\ttrain-mae:1085.191650\teval-mae:1151.377686\n",
      "[80]\ttrain-mae:1084.479248\teval-mae:1151.360718\n",
      "[81]\ttrain-mae:1084.091675\teval-mae:1151.326782\n",
      "[82]\ttrain-mae:1083.204102\teval-mae:1151.272095\n",
      "[83]\ttrain-mae:1082.685303\teval-mae:1151.141968\n",
      "[84]\ttrain-mae:1082.325439\teval-mae:1151.201172\n",
      "[85]\ttrain-mae:1081.534912\teval-mae:1151.167358\n",
      "[86]\ttrain-mae:1080.672485\teval-mae:1151.070557\n",
      "[87]\ttrain-mae:1079.808350\teval-mae:1150.961304\n",
      "[88]\ttrain-mae:1079.270508\teval-mae:1150.626465\n",
      "[89]\ttrain-mae:1078.279663\teval-mae:1150.539917\n",
      "[90]\ttrain-mae:1077.740479\teval-mae:1150.532471\n",
      "[91]\ttrain-mae:1076.721436\teval-mae:1150.506348\n",
      "[92]\ttrain-mae:1076.031982\teval-mae:1150.457642\n",
      "[93]\ttrain-mae:1075.347290\teval-mae:1150.262329\n",
      "[94]\ttrain-mae:1074.709717\teval-mae:1150.171631\n",
      "[95]\ttrain-mae:1074.047241\teval-mae:1150.058472\n",
      "[96]\ttrain-mae:1073.019165\teval-mae:1149.974854\n",
      "[97]\ttrain-mae:1072.626343\teval-mae:1149.910400\n",
      "[98]\ttrain-mae:1071.773560\teval-mae:1149.722778\n",
      "[99]\ttrain-mae:1071.521851\teval-mae:1149.690918\n",
      "[100]\ttrain-mae:1071.351562\teval-mae:1149.705322\n",
      "[101]\ttrain-mae:1070.784546\teval-mae:1149.688232\n",
      "[102]\ttrain-mae:1069.985229\teval-mae:1149.529053\n",
      "[103]\ttrain-mae:1069.591309\teval-mae:1149.394653\n",
      "[104]\ttrain-mae:1068.970093\teval-mae:1149.346069\n",
      "[105]\ttrain-mae:1068.481079\teval-mae:1149.118530\n",
      "[106]\ttrain-mae:1067.851807\teval-mae:1149.037842\n",
      "[107]\ttrain-mae:1067.128174\teval-mae:1148.909790\n",
      "[108]\ttrain-mae:1066.666504\teval-mae:1148.900879\n",
      "[109]\ttrain-mae:1066.234863\teval-mae:1148.910767\n",
      "[110]\ttrain-mae:1065.552246\teval-mae:1148.805420\n",
      "[111]\ttrain-mae:1065.012085\teval-mae:1148.700928\n",
      "[112]\ttrain-mae:1064.608032\teval-mae:1148.709229\n",
      "[113]\ttrain-mae:1063.285034\teval-mae:1148.134033\n",
      "[114]\ttrain-mae:1063.007080\teval-mae:1148.004517\n",
      "[115]\ttrain-mae:1062.667725\teval-mae:1147.966919\n",
      "[116]\ttrain-mae:1062.327881\teval-mae:1147.898926\n",
      "[117]\ttrain-mae:1061.622681\teval-mae:1147.937744\n",
      "[118]\ttrain-mae:1061.049438\teval-mae:1147.853027\n",
      "[119]\ttrain-mae:1060.487793\teval-mae:1147.769775\n",
      "[120]\ttrain-mae:1059.829224\teval-mae:1147.653687\n",
      "[121]\ttrain-mae:1059.436035\teval-mae:1147.633911\n",
      "[122]\ttrain-mae:1058.662964\teval-mae:1147.482910\n",
      "[123]\ttrain-mae:1058.339722\teval-mae:1147.446289\n",
      "[124]\ttrain-mae:1058.220459\teval-mae:1147.416260\n",
      "[125]\ttrain-mae:1057.568359\teval-mae:1147.453979\n",
      "[126]\ttrain-mae:1057.180176\teval-mae:1147.456299\n",
      "[127]\ttrain-mae:1056.868652\teval-mae:1147.498169\n",
      "[128]\ttrain-mae:1056.289795\teval-mae:1147.526001\n",
      "[129]\ttrain-mae:1055.703857\teval-mae:1147.375488\n",
      "[130]\ttrain-mae:1055.279785\teval-mae:1147.314453\n",
      "[131]\ttrain-mae:1054.829346\teval-mae:1147.302002\n",
      "[132]\ttrain-mae:1054.431641\teval-mae:1147.321411\n",
      "[133]\ttrain-mae:1054.245361\teval-mae:1147.338501\n",
      "[134]\ttrain-mae:1053.821167\teval-mae:1147.387329\n",
      "[135]\ttrain-mae:1053.435303\teval-mae:1147.345581\n",
      "[136]\ttrain-mae:1053.051392\teval-mae:1147.366211\n",
      "[137]\ttrain-mae:1052.559814\teval-mae:1147.321533\n",
      "[138]\ttrain-mae:1052.465332\teval-mae:1147.318481\n",
      "[139]\ttrain-mae:1051.884644\teval-mae:1147.040894\n",
      "[140]\ttrain-mae:1051.527710\teval-mae:1147.140869\n",
      "[141]\ttrain-mae:1051.230347\teval-mae:1147.154541\n",
      "[142]\ttrain-mae:1050.986450\teval-mae:1147.197754\n",
      "[143]\ttrain-mae:1050.638916\teval-mae:1147.274658\n",
      "[144]\ttrain-mae:1050.420898\teval-mae:1147.296265\n",
      "[145]\ttrain-mae:1050.025391\teval-mae:1147.268555\n",
      "[146]\ttrain-mae:1049.486694\teval-mae:1147.051392\n",
      "[147]\ttrain-mae:1049.219482\teval-mae:1146.941528\n",
      "[148]\ttrain-mae:1048.646484\teval-mae:1147.029053\n",
      "[149]\ttrain-mae:1048.454468\teval-mae:1146.934570\n",
      "[150]\ttrain-mae:1047.552979\teval-mae:1146.931641\n",
      "[151]\ttrain-mae:1046.927612\teval-mae:1146.804077\n",
      "[152]\ttrain-mae:1046.400635\teval-mae:1146.864624\n",
      "[153]\ttrain-mae:1046.025391\teval-mae:1146.750977\n",
      "[154]\ttrain-mae:1045.595947\teval-mae:1146.705322\n",
      "[155]\ttrain-mae:1045.009521\teval-mae:1146.671875\n",
      "[156]\ttrain-mae:1044.359131\teval-mae:1146.761841\n",
      "[157]\ttrain-mae:1043.860474\teval-mae:1146.788208\n",
      "[158]\ttrain-mae:1042.832031\teval-mae:1146.882202\n",
      "[159]\ttrain-mae:1041.759521\teval-mae:1146.605103\n",
      "[160]\ttrain-mae:1040.501099\teval-mae:1146.315674\n",
      "[161]\ttrain-mae:1040.245972\teval-mae:1146.336182\n",
      "[162]\ttrain-mae:1039.878906\teval-mae:1146.448975\n",
      "[163]\ttrain-mae:1039.532104\teval-mae:1146.427246\n",
      "[164]\ttrain-mae:1038.829712\teval-mae:1146.363403\n",
      "[165]\ttrain-mae:1038.383423\teval-mae:1146.191650\n",
      "[166]\ttrain-mae:1037.558960\teval-mae:1146.211304\n",
      "[167]\ttrain-mae:1037.139160\teval-mae:1146.202393\n",
      "[168]\ttrain-mae:1036.658447\teval-mae:1146.134521\n",
      "[169]\ttrain-mae:1036.326294\teval-mae:1146.166992\n",
      "[170]\ttrain-mae:1035.879150\teval-mae:1146.114502\n",
      "[171]\ttrain-mae:1035.367065\teval-mae:1145.991455\n",
      "[172]\ttrain-mae:1034.915039\teval-mae:1146.009521\n",
      "[173]\ttrain-mae:1034.263550\teval-mae:1146.080811\n",
      "[174]\ttrain-mae:1033.784058\teval-mae:1146.224243\n",
      "[175]\ttrain-mae:1033.584473\teval-mae:1146.309326\n",
      "[176]\ttrain-mae:1032.958008\teval-mae:1146.213501\n",
      "[177]\ttrain-mae:1032.338623\teval-mae:1146.210327\n",
      "[178]\ttrain-mae:1031.523315\teval-mae:1146.357544\n",
      "[179]\ttrain-mae:1031.001831\teval-mae:1146.447144\n",
      "[180]\ttrain-mae:1030.451294\teval-mae:1146.531250\n",
      "[181]\ttrain-mae:1030.046387\teval-mae:1146.526978\n",
      "[182]\ttrain-mae:1029.495239\teval-mae:1146.626343\n",
      "[183]\ttrain-mae:1029.099365\teval-mae:1146.620728\n",
      "[184]\ttrain-mae:1028.743774\teval-mae:1146.647461\n",
      "[185]\ttrain-mae:1028.075317\teval-mae:1146.663574\n",
      "[186]\ttrain-mae:1027.834839\teval-mae:1146.589478\n",
      "[187]\ttrain-mae:1027.340088\teval-mae:1146.684204\n",
      "[188]\ttrain-mae:1026.740356\teval-mae:1147.008911\n",
      "[189]\ttrain-mae:1026.284424\teval-mae:1147.028076\n",
      "[190]\ttrain-mae:1026.055664\teval-mae:1147.058960\n",
      "[191]\ttrain-mae:1025.805664\teval-mae:1147.174805\n",
      "[192]\ttrain-mae:1025.137817\teval-mae:1146.974976\n",
      "[193]\ttrain-mae:1024.594849\teval-mae:1147.123169\n",
      "[194]\ttrain-mae:1024.310059\teval-mae:1147.161255\n",
      "[195]\ttrain-mae:1023.616943\teval-mae:1147.173462\n",
      "[196]\ttrain-mae:1023.138611\teval-mae:1147.284790\n",
      "Stopping. Best iteration:\n",
      "[171]\ttrain-mae:1035.367065\teval-mae:1145.991455\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mae:3184.548340\teval-mae:3197.471436\n",
      "[1]\ttrain-mae:3073.072021\teval-mae:3086.125732\n",
      "[2]\ttrain-mae:2923.979248\teval-mae:2937.350342\n",
      "[3]\ttrain-mae:2757.820312\teval-mae:2771.503418\n",
      "[4]\ttrain-mae:2587.673584\teval-mae:2601.632568\n",
      "[5]\ttrain-mae:2422.003174\teval-mae:2436.452881\n",
      "[6]\ttrain-mae:2266.151611\teval-mae:2281.280518\n",
      "[7]\ttrain-mae:2122.335449\teval-mae:2138.089111\n",
      "[8]\ttrain-mae:1992.214844\teval-mae:2008.838989\n",
      "[9]\ttrain-mae:1875.395386\teval-mae:1893.440308\n",
      "[10]\ttrain-mae:1771.131836\teval-mae:1790.849854\n",
      "[11]\ttrain-mae:1680.104614\teval-mae:1701.247192\n",
      "[12]\ttrain-mae:1601.750366\teval-mae:1624.218384\n",
      "[13]\ttrain-mae:1533.356934\teval-mae:1557.124390\n",
      "[14]\ttrain-mae:1474.954956\teval-mae:1500.467529\n",
      "[15]\ttrain-mae:1424.557129\teval-mae:1451.949219\n",
      "[16]\ttrain-mae:1381.198608\teval-mae:1410.120239\n",
      "[17]\ttrain-mae:1344.684814\teval-mae:1375.332886\n",
      "[18]\ttrain-mae:1313.304443\teval-mae:1345.258301\n",
      "[19]\ttrain-mae:1286.081421\teval-mae:1319.580322\n",
      "[20]\ttrain-mae:1263.654419\teval-mae:1298.140015\n",
      "[21]\ttrain-mae:1243.867432\teval-mae:1279.705933\n",
      "[22]\ttrain-mae:1227.680664\teval-mae:1264.843994\n",
      "[23]\ttrain-mae:1213.795898\teval-mae:1252.097656\n",
      "[24]\ttrain-mae:1201.997070\teval-mae:1241.185669\n",
      "[25]\ttrain-mae:1191.594116\teval-mae:1231.955811\n",
      "[26]\ttrain-mae:1182.684570\teval-mae:1223.818359\n",
      "[27]\ttrain-mae:1175.270142\teval-mae:1217.321167\n",
      "[28]\ttrain-mae:1168.677979\teval-mae:1211.536865\n",
      "[29]\ttrain-mae:1162.689453\teval-mae:1206.695679\n",
      "[30]\ttrain-mae:1157.495605\teval-mae:1202.364258\n",
      "[31]\ttrain-mae:1152.925049\teval-mae:1198.578857\n",
      "[32]\ttrain-mae:1148.920166\teval-mae:1195.514893\n",
      "[33]\ttrain-mae:1145.383423\teval-mae:1192.706299\n",
      "[34]\ttrain-mae:1142.537598\teval-mae:1190.615234\n",
      "[35]\ttrain-mae:1139.738770\teval-mae:1188.545532\n",
      "[36]\ttrain-mae:1137.053833\teval-mae:1186.775757\n",
      "[37]\ttrain-mae:1135.065063\teval-mae:1185.380737\n",
      "[38]\ttrain-mae:1133.251343\teval-mae:1183.858643\n",
      "[39]\ttrain-mae:1130.995850\teval-mae:1182.473389\n",
      "[40]\ttrain-mae:1129.092651\teval-mae:1181.675781\n",
      "[41]\ttrain-mae:1126.292725\teval-mae:1179.836304\n",
      "[42]\ttrain-mae:1124.355835\teval-mae:1178.716064\n",
      "[43]\ttrain-mae:1122.690308\teval-mae:1177.883423\n",
      "[44]\ttrain-mae:1121.261597\teval-mae:1177.147461\n",
      "[45]\ttrain-mae:1119.336670\teval-mae:1176.287964\n",
      "[46]\ttrain-mae:1117.378784\teval-mae:1175.319946\n",
      "[47]\ttrain-mae:1115.110107\teval-mae:1173.830566\n",
      "[48]\ttrain-mae:1113.922974\teval-mae:1173.370117\n",
      "[49]\ttrain-mae:1111.836914\teval-mae:1172.556763\n",
      "[50]\ttrain-mae:1111.000854\teval-mae:1172.101685\n",
      "[51]\ttrain-mae:1108.832642\teval-mae:1170.806641\n",
      "[52]\ttrain-mae:1107.875732\teval-mae:1170.393433\n",
      "[53]\ttrain-mae:1106.705933\teval-mae:1169.976685\n",
      "[54]\ttrain-mae:1104.931763\teval-mae:1169.013306\n",
      "[55]\ttrain-mae:1103.386230\teval-mae:1168.593018\n",
      "[56]\ttrain-mae:1102.081177\teval-mae:1168.008545\n",
      "[57]\ttrain-mae:1101.473633\teval-mae:1167.708740\n",
      "[58]\ttrain-mae:1100.156006\teval-mae:1167.303101\n",
      "[59]\ttrain-mae:1099.409058\teval-mae:1166.987183\n",
      "[60]\ttrain-mae:1098.152710\teval-mae:1166.430420\n",
      "[61]\ttrain-mae:1097.672729\teval-mae:1166.264038\n",
      "[62]\ttrain-mae:1096.705322\teval-mae:1165.972534\n",
      "[63]\ttrain-mae:1095.295288\teval-mae:1165.537354\n",
      "[64]\ttrain-mae:1094.322876\teval-mae:1165.327881\n",
      "[65]\ttrain-mae:1093.512939\teval-mae:1165.127319\n",
      "[66]\ttrain-mae:1092.532715\teval-mae:1164.726196\n",
      "[67]\ttrain-mae:1091.953247\teval-mae:1164.392090\n",
      "[68]\ttrain-mae:1090.941528\teval-mae:1164.198364\n",
      "[69]\ttrain-mae:1090.526001\teval-mae:1164.073120\n",
      "[70]\ttrain-mae:1090.092163\teval-mae:1163.979370\n",
      "[71]\ttrain-mae:1089.545776\teval-mae:1163.845337\n",
      "[72]\ttrain-mae:1089.134644\teval-mae:1163.745972\n",
      "[73]\ttrain-mae:1088.602051\teval-mae:1163.456421\n",
      "[74]\ttrain-mae:1087.875977\teval-mae:1163.366821\n",
      "[75]\ttrain-mae:1087.136841\teval-mae:1163.215820\n",
      "[76]\ttrain-mae:1086.439819\teval-mae:1163.058594\n",
      "[77]\ttrain-mae:1085.940552\teval-mae:1163.143433\n",
      "[78]\ttrain-mae:1085.073853\teval-mae:1162.910034\n",
      "[79]\ttrain-mae:1083.727661\teval-mae:1162.130737\n",
      "[80]\ttrain-mae:1082.729370\teval-mae:1162.185791\n",
      "[81]\ttrain-mae:1082.466919\teval-mae:1162.217041\n",
      "[82]\ttrain-mae:1081.715698\teval-mae:1161.989624\n",
      "[83]\ttrain-mae:1081.101807\teval-mae:1161.819702\n",
      "[84]\ttrain-mae:1080.045288\teval-mae:1161.578857\n",
      "[85]\ttrain-mae:1079.323975\teval-mae:1161.455444\n",
      "[86]\ttrain-mae:1078.423340\teval-mae:1161.275513\n",
      "[87]\ttrain-mae:1077.862061\teval-mae:1161.392334\n",
      "[88]\ttrain-mae:1077.564941\teval-mae:1161.330933\n",
      "[89]\ttrain-mae:1076.388062\teval-mae:1161.183594\n",
      "[90]\ttrain-mae:1075.571655\teval-mae:1161.104126\n",
      "[91]\ttrain-mae:1074.772583\teval-mae:1161.049683\n",
      "[92]\ttrain-mae:1073.922852\teval-mae:1160.953003\n",
      "[93]\ttrain-mae:1073.167969\teval-mae:1160.786377\n",
      "[94]\ttrain-mae:1072.459717\teval-mae:1160.571899\n",
      "[95]\ttrain-mae:1071.884399\teval-mae:1160.697998\n",
      "[96]\ttrain-mae:1071.489014\teval-mae:1160.636597\n",
      "[97]\ttrain-mae:1071.211426\teval-mae:1160.583252\n",
      "[98]\ttrain-mae:1070.467285\teval-mae:1160.473022\n",
      "[99]\ttrain-mae:1070.130005\teval-mae:1160.446167\n",
      "[100]\ttrain-mae:1069.371460\teval-mae:1160.293823\n",
      "[101]\ttrain-mae:1068.844360\teval-mae:1160.080811\n",
      "[102]\ttrain-mae:1068.030640\teval-mae:1159.760986\n",
      "[103]\ttrain-mae:1066.838745\teval-mae:1159.556641\n",
      "[104]\ttrain-mae:1066.552246\teval-mae:1159.577881\n",
      "[105]\ttrain-mae:1065.770264\teval-mae:1159.620483\n",
      "[106]\ttrain-mae:1065.343994\teval-mae:1159.559204\n",
      "[107]\ttrain-mae:1064.572998\teval-mae:1159.477417\n",
      "[108]\ttrain-mae:1062.884888\teval-mae:1159.131104\n",
      "[109]\ttrain-mae:1062.386597\teval-mae:1159.121094\n",
      "[110]\ttrain-mae:1061.120605\teval-mae:1158.587402\n",
      "[111]\ttrain-mae:1060.778687\teval-mae:1158.538330\n",
      "[112]\ttrain-mae:1059.776978\teval-mae:1158.409668\n",
      "[113]\ttrain-mae:1059.609375\teval-mae:1158.270996\n",
      "[114]\ttrain-mae:1059.133667\teval-mae:1158.240601\n",
      "[115]\ttrain-mae:1058.522339\teval-mae:1158.205322\n",
      "[116]\ttrain-mae:1057.848389\teval-mae:1158.325073\n",
      "[117]\ttrain-mae:1057.219971\teval-mae:1158.271851\n",
      "[118]\ttrain-mae:1056.560547\teval-mae:1158.383423\n",
      "[119]\ttrain-mae:1055.998169\teval-mae:1158.382568\n",
      "[120]\ttrain-mae:1055.290039\teval-mae:1158.170166\n",
      "[121]\ttrain-mae:1054.746094\teval-mae:1158.101440\n",
      "[122]\ttrain-mae:1053.982422\teval-mae:1158.013428\n",
      "[123]\ttrain-mae:1053.549316\teval-mae:1158.064087\n",
      "[124]\ttrain-mae:1053.320923\teval-mae:1158.082642\n",
      "[125]\ttrain-mae:1052.382080\teval-mae:1157.748779\n",
      "[126]\ttrain-mae:1051.686646\teval-mae:1157.700806\n",
      "[127]\ttrain-mae:1051.445923\teval-mae:1157.684082\n",
      "[128]\ttrain-mae:1051.034912\teval-mae:1157.801880\n",
      "[129]\ttrain-mae:1050.620605\teval-mae:1157.718506\n",
      "[130]\ttrain-mae:1050.151611\teval-mae:1157.797241\n",
      "[131]\ttrain-mae:1049.833862\teval-mae:1157.866577\n",
      "[132]\ttrain-mae:1049.533203\teval-mae:1157.794434\n",
      "[133]\ttrain-mae:1049.430298\teval-mae:1157.818970\n",
      "[134]\ttrain-mae:1048.645752\teval-mae:1157.811768\n",
      "[135]\ttrain-mae:1048.166016\teval-mae:1157.684326\n",
      "[136]\ttrain-mae:1047.705200\teval-mae:1157.687500\n",
      "[137]\ttrain-mae:1047.302612\teval-mae:1157.680542\n",
      "[138]\ttrain-mae:1047.161987\teval-mae:1157.623413\n",
      "[139]\ttrain-mae:1046.661255\teval-mae:1157.645020\n",
      "[140]\ttrain-mae:1045.928345\teval-mae:1157.581055\n",
      "[141]\ttrain-mae:1045.549927\teval-mae:1157.536621\n",
      "[142]\ttrain-mae:1045.193359\teval-mae:1157.548340\n",
      "[143]\ttrain-mae:1044.672363\teval-mae:1157.554077\n",
      "[144]\ttrain-mae:1044.355957\teval-mae:1157.453857\n",
      "[145]\ttrain-mae:1043.757690\teval-mae:1157.453857\n",
      "[146]\ttrain-mae:1043.413330\teval-mae:1157.446899\n",
      "[147]\ttrain-mae:1042.889648\teval-mae:1157.566895\n",
      "[148]\ttrain-mae:1042.540649\teval-mae:1157.475952\n",
      "[149]\ttrain-mae:1042.121948\teval-mae:1157.369995\n",
      "[150]\ttrain-mae:1041.377197\teval-mae:1157.308350\n",
      "[151]\ttrain-mae:1040.749390\teval-mae:1157.261230\n",
      "[152]\ttrain-mae:1040.196899\teval-mae:1157.317139\n",
      "[153]\ttrain-mae:1039.954346\teval-mae:1157.210815\n",
      "[154]\ttrain-mae:1039.768677\teval-mae:1157.228271\n",
      "[155]\ttrain-mae:1039.012573\teval-mae:1157.353516\n",
      "[156]\ttrain-mae:1038.488892\teval-mae:1157.316528\n",
      "[157]\ttrain-mae:1038.162964\teval-mae:1157.423340\n",
      "[158]\ttrain-mae:1037.768188\teval-mae:1157.421387\n",
      "[159]\ttrain-mae:1037.318970\teval-mae:1157.450806\n",
      "[160]\ttrain-mae:1036.705078\teval-mae:1157.409058\n",
      "[161]\ttrain-mae:1036.349854\teval-mae:1157.378662\n",
      "[162]\ttrain-mae:1036.068726\teval-mae:1157.305908\n",
      "[163]\ttrain-mae:1035.656860\teval-mae:1157.213745\n",
      "[164]\ttrain-mae:1034.793213\teval-mae:1157.275757\n",
      "[165]\ttrain-mae:1034.502930\teval-mae:1157.254517\n",
      "[166]\ttrain-mae:1033.941528\teval-mae:1157.287231\n",
      "[167]\ttrain-mae:1033.374634\teval-mae:1157.279907\n",
      "[168]\ttrain-mae:1032.860352\teval-mae:1157.174072\n",
      "[169]\ttrain-mae:1032.716064\teval-mae:1157.088135\n",
      "[170]\ttrain-mae:1031.998169\teval-mae:1157.087280\n",
      "[171]\ttrain-mae:1030.953247\teval-mae:1156.935181\n",
      "[172]\ttrain-mae:1030.579590\teval-mae:1157.015503\n",
      "[173]\ttrain-mae:1029.942261\teval-mae:1157.006348\n",
      "[174]\ttrain-mae:1029.313232\teval-mae:1157.069824\n",
      "[175]\ttrain-mae:1028.798950\teval-mae:1157.098755\n",
      "[176]\ttrain-mae:1028.380249\teval-mae:1157.227783\n",
      "[177]\ttrain-mae:1028.132935\teval-mae:1157.187134\n",
      "[178]\ttrain-mae:1027.602295\teval-mae:1157.292236\n",
      "[179]\ttrain-mae:1026.848511\teval-mae:1157.290527\n",
      "[180]\ttrain-mae:1026.182007\teval-mae:1157.300903\n",
      "[181]\ttrain-mae:1025.772095\teval-mae:1157.279053\n",
      "[182]\ttrain-mae:1025.536865\teval-mae:1157.376221\n",
      "[183]\ttrain-mae:1025.237427\teval-mae:1157.374268\n",
      "[184]\ttrain-mae:1025.170776\teval-mae:1157.379761\n",
      "[185]\ttrain-mae:1024.709717\teval-mae:1157.400757\n",
      "[186]\ttrain-mae:1024.156250\teval-mae:1157.378418\n",
      "[187]\ttrain-mae:1023.760925\teval-mae:1157.384521\n",
      "[188]\ttrain-mae:1023.425781\teval-mae:1157.514526\n",
      "[189]\ttrain-mae:1023.099731\teval-mae:1157.587280\n",
      "[190]\ttrain-mae:1023.016663\teval-mae:1157.517700\n",
      "[191]\ttrain-mae:1022.752014\teval-mae:1157.543457\n",
      "[192]\ttrain-mae:1022.252747\teval-mae:1157.527344\n",
      "[193]\ttrain-mae:1021.829834\teval-mae:1157.598389\n",
      "[194]\ttrain-mae:1021.530640\teval-mae:1157.577026\n",
      "[195]\ttrain-mae:1021.001038\teval-mae:1157.485718\n",
      "[196]\ttrain-mae:1020.656494\teval-mae:1157.483765\n",
      "Stopping. Best iteration:\n",
      "[171]\ttrain-mae:1030.953247\teval-mae:1156.935181\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mae:3185.954346\teval-mae:3191.943115\n",
      "[1]\ttrain-mae:3075.730713\teval-mae:3081.895752\n",
      "[2]\ttrain-mae:2926.257324\teval-mae:2932.371582\n",
      "[3]\ttrain-mae:2759.001221\teval-mae:2764.948975\n",
      "[4]\ttrain-mae:2588.197754\teval-mae:2594.354492\n",
      "[5]\ttrain-mae:2421.023438\teval-mae:2427.363037\n",
      "[6]\ttrain-mae:2264.074463\teval-mae:2270.848633\n",
      "[7]\ttrain-mae:2119.577881\teval-mae:2127.162598\n",
      "[8]\ttrain-mae:1988.101562\teval-mae:1996.929810\n",
      "[9]\ttrain-mae:1871.664307\teval-mae:1882.122559\n",
      "[10]\ttrain-mae:1767.872437\teval-mae:1780.374023\n",
      "[11]\ttrain-mae:1677.421997\teval-mae:1691.853882\n",
      "[12]\ttrain-mae:1599.105713\teval-mae:1615.754639\n",
      "[13]\ttrain-mae:1530.412720\teval-mae:1549.158325\n",
      "[14]\ttrain-mae:1472.254761\teval-mae:1492.823242\n",
      "[15]\ttrain-mae:1421.597290\teval-mae:1444.057861\n",
      "[16]\ttrain-mae:1379.253784\teval-mae:1403.041626\n",
      "[17]\ttrain-mae:1343.738770\teval-mae:1368.971191\n",
      "[18]\ttrain-mae:1312.616211\teval-mae:1339.604736\n",
      "[19]\ttrain-mae:1286.115479\teval-mae:1314.636475\n",
      "[20]\ttrain-mae:1263.447510\teval-mae:1293.541382\n",
      "[21]\ttrain-mae:1244.415039\teval-mae:1275.573120\n",
      "[22]\ttrain-mae:1228.589966\teval-mae:1260.660034\n",
      "[23]\ttrain-mae:1214.382812\teval-mae:1247.831177\n",
      "[24]\ttrain-mae:1202.453247\teval-mae:1237.294434\n",
      "[25]\ttrain-mae:1191.896484\teval-mae:1228.053467\n",
      "[26]\ttrain-mae:1183.016357\teval-mae:1220.322876\n",
      "[27]\ttrain-mae:1175.745483\teval-mae:1214.292236\n",
      "[28]\ttrain-mae:1168.252930\teval-mae:1208.482056\n",
      "[29]\ttrain-mae:1162.178345\teval-mae:1203.469360\n",
      "[30]\ttrain-mae:1157.581543\teval-mae:1199.973267\n",
      "[31]\ttrain-mae:1152.658081\teval-mae:1196.260132\n",
      "[32]\ttrain-mae:1147.824585\teval-mae:1192.661499\n",
      "[33]\ttrain-mae:1143.478027\teval-mae:1189.504395\n",
      "[34]\ttrain-mae:1140.482300\teval-mae:1187.310425\n",
      "[35]\ttrain-mae:1137.400879\teval-mae:1185.302124\n",
      "[36]\ttrain-mae:1135.497925\teval-mae:1183.903931\n",
      "[37]\ttrain-mae:1133.267700\teval-mae:1182.435547\n",
      "[38]\ttrain-mae:1131.002441\teval-mae:1181.209351\n",
      "[39]\ttrain-mae:1128.065796\teval-mae:1179.475464\n",
      "[40]\ttrain-mae:1126.212280\teval-mae:1178.091919\n",
      "[41]\ttrain-mae:1124.416382\teval-mae:1177.166748\n",
      "[42]\ttrain-mae:1122.561401\teval-mae:1176.317749\n",
      "[43]\ttrain-mae:1121.443726\teval-mae:1175.582031\n",
      "[44]\ttrain-mae:1119.992676\teval-mae:1174.874146\n",
      "[45]\ttrain-mae:1118.831177\teval-mae:1174.417480\n",
      "[46]\ttrain-mae:1117.544067\teval-mae:1173.848022\n",
      "[47]\ttrain-mae:1115.646729\teval-mae:1172.570801\n",
      "[48]\ttrain-mae:1113.951538\teval-mae:1171.805420\n",
      "[49]\ttrain-mae:1112.865356\teval-mae:1171.152344\n",
      "[50]\ttrain-mae:1111.513794\teval-mae:1170.644775\n",
      "[51]\ttrain-mae:1109.875000\teval-mae:1169.911865\n",
      "[52]\ttrain-mae:1108.295532\teval-mae:1169.290405\n",
      "[53]\ttrain-mae:1107.403198\teval-mae:1168.861084\n",
      "[54]\ttrain-mae:1106.835815\teval-mae:1168.443604\n",
      "[55]\ttrain-mae:1105.692505\teval-mae:1167.882812\n",
      "[56]\ttrain-mae:1104.190552\teval-mae:1166.990479\n",
      "[57]\ttrain-mae:1102.817627\teval-mae:1166.333130\n",
      "[58]\ttrain-mae:1101.855591\teval-mae:1166.128418\n",
      "[59]\ttrain-mae:1100.618896\teval-mae:1165.913452\n",
      "[60]\ttrain-mae:1099.964233\teval-mae:1165.652832\n",
      "[61]\ttrain-mae:1098.990967\teval-mae:1165.303955\n",
      "[62]\ttrain-mae:1097.733765\teval-mae:1164.945801\n",
      "[63]\ttrain-mae:1096.299561\teval-mae:1164.464600\n",
      "[64]\ttrain-mae:1095.784302\teval-mae:1164.322754\n",
      "[65]\ttrain-mae:1095.057739\teval-mae:1164.057373\n",
      "[66]\ttrain-mae:1094.206665\teval-mae:1163.868530\n",
      "[67]\ttrain-mae:1093.602539\teval-mae:1163.712646\n",
      "[68]\ttrain-mae:1092.083496\teval-mae:1163.354614\n",
      "[69]\ttrain-mae:1091.507202\teval-mae:1163.187866\n",
      "[70]\ttrain-mae:1090.581665\teval-mae:1162.931030\n",
      "[71]\ttrain-mae:1089.809814\teval-mae:1162.645874\n",
      "[72]\ttrain-mae:1089.078003\teval-mae:1162.407593\n",
      "[73]\ttrain-mae:1088.054688\teval-mae:1162.116577\n",
      "[74]\ttrain-mae:1087.479980\teval-mae:1161.917480\n",
      "[75]\ttrain-mae:1086.915894\teval-mae:1161.832520\n",
      "[76]\ttrain-mae:1085.950439\teval-mae:1161.745972\n",
      "[77]\ttrain-mae:1084.986328\teval-mae:1161.428345\n",
      "[78]\ttrain-mae:1084.382080\teval-mae:1161.349365\n",
      "[79]\ttrain-mae:1083.932739\teval-mae:1161.263916\n",
      "[80]\ttrain-mae:1083.526123\teval-mae:1161.183594\n",
      "[81]\ttrain-mae:1083.043457\teval-mae:1161.014526\n",
      "[82]\ttrain-mae:1082.206299\teval-mae:1160.730713\n",
      "[83]\ttrain-mae:1081.489136\teval-mae:1160.528564\n",
      "[84]\ttrain-mae:1080.823242\teval-mae:1160.401001\n",
      "[85]\ttrain-mae:1079.807861\teval-mae:1160.327515\n",
      "[86]\ttrain-mae:1078.989990\teval-mae:1160.066650\n",
      "[87]\ttrain-mae:1078.423706\teval-mae:1159.975342\n",
      "[88]\ttrain-mae:1077.939697\teval-mae:1159.746826\n",
      "[89]\ttrain-mae:1077.434692\teval-mae:1159.625000\n",
      "[90]\ttrain-mae:1076.665894\teval-mae:1159.552979\n",
      "[91]\ttrain-mae:1075.808716\teval-mae:1159.440063\n",
      "[92]\ttrain-mae:1074.968506\teval-mae:1159.130981\n",
      "[93]\ttrain-mae:1074.292847\teval-mae:1158.687012\n",
      "[94]\ttrain-mae:1073.245972\teval-mae:1158.473877\n",
      "[95]\ttrain-mae:1072.679810\teval-mae:1158.426270\n",
      "[96]\ttrain-mae:1072.200195\teval-mae:1158.387573\n",
      "[97]\ttrain-mae:1071.396362\teval-mae:1158.303467\n",
      "[98]\ttrain-mae:1071.224487\teval-mae:1158.326050\n",
      "[99]\ttrain-mae:1070.825317\teval-mae:1158.182129\n",
      "[100]\ttrain-mae:1070.175659\teval-mae:1158.188843\n",
      "[101]\ttrain-mae:1069.456055\teval-mae:1158.226074\n",
      "[102]\ttrain-mae:1069.019043\teval-mae:1158.185547\n",
      "[103]\ttrain-mae:1068.632690\teval-mae:1158.217285\n",
      "[104]\ttrain-mae:1068.103027\teval-mae:1158.036499\n",
      "[105]\ttrain-mae:1066.927124\teval-mae:1157.662231\n",
      "[106]\ttrain-mae:1066.511841\teval-mae:1157.672485\n",
      "[107]\ttrain-mae:1066.373535\teval-mae:1157.599609\n",
      "[108]\ttrain-mae:1065.939697\teval-mae:1157.404785\n",
      "[109]\ttrain-mae:1065.440063\teval-mae:1157.397339\n",
      "[110]\ttrain-mae:1064.845825\teval-mae:1157.481934\n",
      "[111]\ttrain-mae:1064.100830\teval-mae:1157.420898\n",
      "[112]\ttrain-mae:1063.508545\teval-mae:1157.519165\n",
      "[113]\ttrain-mae:1062.566772\teval-mae:1157.495972\n",
      "[114]\ttrain-mae:1062.091553\teval-mae:1157.553589\n",
      "[115]\ttrain-mae:1061.650757\teval-mae:1157.630859\n",
      "[116]\ttrain-mae:1061.365356\teval-mae:1157.583740\n",
      "[117]\ttrain-mae:1060.392578\teval-mae:1157.374146\n",
      "[118]\ttrain-mae:1059.509644\teval-mae:1157.236328\n",
      "[119]\ttrain-mae:1059.042725\teval-mae:1157.267456\n",
      "[120]\ttrain-mae:1058.408691\teval-mae:1157.198120\n",
      "[121]\ttrain-mae:1057.821533\teval-mae:1157.295654\n",
      "[122]\ttrain-mae:1057.462769\teval-mae:1157.365112\n",
      "[123]\ttrain-mae:1056.905273\teval-mae:1157.182373\n",
      "[124]\ttrain-mae:1056.229980\teval-mae:1157.159180\n",
      "[125]\ttrain-mae:1055.872559\teval-mae:1157.109985\n",
      "[126]\ttrain-mae:1055.413086\teval-mae:1157.307617\n",
      "[127]\ttrain-mae:1054.791870\teval-mae:1157.153809\n",
      "[128]\ttrain-mae:1054.208862\teval-mae:1157.074951\n",
      "[129]\ttrain-mae:1053.642090\teval-mae:1156.901611\n",
      "[130]\ttrain-mae:1053.345825\teval-mae:1156.908325\n",
      "[131]\ttrain-mae:1052.838013\teval-mae:1156.929565\n",
      "[132]\ttrain-mae:1052.209473\teval-mae:1157.057495\n",
      "[133]\ttrain-mae:1051.751831\teval-mae:1157.029297\n",
      "[134]\ttrain-mae:1051.097412\teval-mae:1156.942871\n",
      "[135]\ttrain-mae:1050.755737\teval-mae:1157.006958\n",
      "[136]\ttrain-mae:1050.268066\teval-mae:1156.961304\n",
      "[137]\ttrain-mae:1049.745239\teval-mae:1157.000000\n",
      "[138]\ttrain-mae:1049.139282\teval-mae:1157.023926\n",
      "[139]\ttrain-mae:1048.620728\teval-mae:1156.963379\n",
      "[140]\ttrain-mae:1048.322754\teval-mae:1156.984863\n",
      "[141]\ttrain-mae:1047.458252\teval-mae:1156.960205\n",
      "[142]\ttrain-mae:1046.842529\teval-mae:1156.905762\n",
      "[143]\ttrain-mae:1046.448120\teval-mae:1156.968506\n",
      "[144]\ttrain-mae:1046.164062\teval-mae:1156.990112\n",
      "[145]\ttrain-mae:1045.405762\teval-mae:1156.883667\n",
      "[146]\ttrain-mae:1045.107056\teval-mae:1156.763794\n",
      "[147]\ttrain-mae:1044.985107\teval-mae:1156.772217\n",
      "[148]\ttrain-mae:1044.666992\teval-mae:1156.851196\n",
      "[149]\ttrain-mae:1044.388550\teval-mae:1156.853516\n",
      "[150]\ttrain-mae:1043.810913\teval-mae:1156.841431\n",
      "[151]\ttrain-mae:1042.955200\teval-mae:1156.849487\n",
      "[152]\ttrain-mae:1042.127197\teval-mae:1156.868042\n",
      "[153]\ttrain-mae:1041.624756\teval-mae:1156.902344\n",
      "[154]\ttrain-mae:1041.271973\teval-mae:1156.936523\n",
      "[155]\ttrain-mae:1040.691772\teval-mae:1156.983765\n",
      "[156]\ttrain-mae:1040.174072\teval-mae:1157.021851\n",
      "[157]\ttrain-mae:1039.539185\teval-mae:1157.030029\n",
      "[158]\ttrain-mae:1038.979370\teval-mae:1156.980347\n",
      "[159]\ttrain-mae:1038.730835\teval-mae:1156.970581\n",
      "[160]\ttrain-mae:1037.832886\teval-mae:1156.827515\n",
      "[161]\ttrain-mae:1037.347534\teval-mae:1156.880493\n",
      "[162]\ttrain-mae:1036.896729\teval-mae:1156.987549\n",
      "[163]\ttrain-mae:1036.472900\teval-mae:1157.005493\n",
      "[164]\ttrain-mae:1035.411865\teval-mae:1156.976929\n",
      "[165]\ttrain-mae:1034.854736\teval-mae:1156.873657\n",
      "[166]\ttrain-mae:1034.632812\teval-mae:1157.011475\n",
      "[167]\ttrain-mae:1034.144531\teval-mae:1156.940552\n",
      "[168]\ttrain-mae:1034.027832\teval-mae:1157.016113\n",
      "[169]\ttrain-mae:1033.580322\teval-mae:1156.902954\n",
      "[170]\ttrain-mae:1032.985474\teval-mae:1156.864258\n",
      "[171]\ttrain-mae:1032.708496\teval-mae:1156.834229\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-mae:1045.107056\teval-mae:1156.763794\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mae:3189.914062\teval-mae:3176.199707\n",
      "[1]\ttrain-mae:3079.788086\teval-mae:3066.241699\n",
      "[2]\ttrain-mae:2930.453125\teval-mae:2917.295654\n",
      "[3]\ttrain-mae:2763.749268\teval-mae:2750.817139\n",
      "[4]\ttrain-mae:2593.195312\teval-mae:2581.004150\n",
      "[5]\ttrain-mae:2426.493896\teval-mae:2415.244629\n",
      "[6]\ttrain-mae:2269.465820\teval-mae:2259.145996\n",
      "[7]\ttrain-mae:2125.014648\teval-mae:2115.965088\n",
      "[8]\ttrain-mae:1994.257324\teval-mae:1986.709473\n",
      "[9]\ttrain-mae:1877.613403\teval-mae:1871.481323\n",
      "[10]\ttrain-mae:1773.151001\teval-mae:1768.141724\n",
      "[11]\ttrain-mae:1682.588379\teval-mae:1678.842529\n",
      "[12]\ttrain-mae:1604.149292\teval-mae:1601.509521\n",
      "[13]\ttrain-mae:1536.007812\teval-mae:1534.552368\n",
      "[14]\ttrain-mae:1477.842773\teval-mae:1477.649414\n",
      "[15]\ttrain-mae:1427.377197\teval-mae:1428.462891\n",
      "[16]\ttrain-mae:1384.948853\teval-mae:1387.201172\n",
      "[17]\ttrain-mae:1348.261963\teval-mae:1352.355469\n",
      "[18]\ttrain-mae:1316.704224\teval-mae:1322.673706\n",
      "[19]\ttrain-mae:1289.968018\teval-mae:1297.611450\n",
      "[20]\ttrain-mae:1266.499268\teval-mae:1275.861450\n",
      "[21]\ttrain-mae:1247.082275\teval-mae:1258.377563\n",
      "[22]\ttrain-mae:1230.499512\teval-mae:1243.299316\n",
      "[23]\ttrain-mae:1216.307861\teval-mae:1230.636230\n",
      "[24]\ttrain-mae:1204.450195\teval-mae:1220.481812\n",
      "[25]\ttrain-mae:1193.443726\teval-mae:1210.979126\n",
      "[26]\ttrain-mae:1184.947266\teval-mae:1203.630127\n",
      "[27]\ttrain-mae:1177.356323\teval-mae:1197.434814\n",
      "[28]\ttrain-mae:1170.308228\teval-mae:1192.321533\n",
      "[29]\ttrain-mae:1163.858154\teval-mae:1187.274902\n",
      "[30]\ttrain-mae:1158.887207\teval-mae:1183.307129\n",
      "[31]\ttrain-mae:1154.136719\teval-mae:1179.773071\n",
      "[32]\ttrain-mae:1150.378906\teval-mae:1177.014648\n",
      "[33]\ttrain-mae:1146.725586\teval-mae:1174.345703\n",
      "[34]\ttrain-mae:1143.938965\teval-mae:1172.336670\n",
      "[35]\ttrain-mae:1140.621338\teval-mae:1170.606079\n",
      "[36]\ttrain-mae:1137.948608\teval-mae:1168.939331\n",
      "[37]\ttrain-mae:1135.563843\teval-mae:1167.748047\n",
      "[38]\ttrain-mae:1133.496948\teval-mae:1166.657471\n",
      "[39]\ttrain-mae:1131.114136\teval-mae:1165.316772\n",
      "[40]\ttrain-mae:1129.001099\teval-mae:1164.166748\n",
      "[41]\ttrain-mae:1126.652710\teval-mae:1163.306152\n",
      "[42]\ttrain-mae:1124.889282\teval-mae:1162.312378\n",
      "[43]\ttrain-mae:1123.603149\teval-mae:1161.543457\n",
      "[44]\ttrain-mae:1122.273926\teval-mae:1160.724365\n",
      "[45]\ttrain-mae:1120.818481\teval-mae:1160.124023\n",
      "[46]\ttrain-mae:1119.927124\teval-mae:1159.698120\n",
      "[47]\ttrain-mae:1118.367920\teval-mae:1159.399414\n",
      "[48]\ttrain-mae:1117.193970\teval-mae:1158.980835\n",
      "[49]\ttrain-mae:1115.765991\teval-mae:1158.383179\n",
      "[50]\ttrain-mae:1114.501221\teval-mae:1157.955078\n",
      "[51]\ttrain-mae:1112.952393\teval-mae:1157.140869\n",
      "[52]\ttrain-mae:1111.233887\teval-mae:1156.432739\n",
      "[53]\ttrain-mae:1110.472168\teval-mae:1156.019043\n",
      "[54]\ttrain-mae:1109.767578\teval-mae:1155.663452\n",
      "[55]\ttrain-mae:1108.192627\teval-mae:1155.116699\n",
      "[56]\ttrain-mae:1106.781616\teval-mae:1154.483032\n",
      "[57]\ttrain-mae:1105.423950\teval-mae:1154.021606\n",
      "[58]\ttrain-mae:1103.991699\teval-mae:1153.656982\n",
      "[59]\ttrain-mae:1102.717773\teval-mae:1153.181519\n",
      "[60]\ttrain-mae:1101.791138\teval-mae:1152.962036\n",
      "[61]\ttrain-mae:1100.348267\teval-mae:1152.278687\n",
      "[62]\ttrain-mae:1099.133301\teval-mae:1152.161011\n",
      "[63]\ttrain-mae:1098.282349\teval-mae:1151.870239\n",
      "[64]\ttrain-mae:1097.431030\teval-mae:1151.840332\n",
      "[65]\ttrain-mae:1096.946533\teval-mae:1151.842163\n",
      "[66]\ttrain-mae:1096.177246\teval-mae:1151.567505\n",
      "[67]\ttrain-mae:1095.246094\teval-mae:1151.511108\n",
      "[68]\ttrain-mae:1094.325806\teval-mae:1151.246704\n",
      "[69]\ttrain-mae:1093.954834\teval-mae:1151.182983\n",
      "[70]\ttrain-mae:1093.064941\teval-mae:1151.083740\n",
      "[71]\ttrain-mae:1092.370850\teval-mae:1150.980591\n",
      "[72]\ttrain-mae:1091.113892\teval-mae:1150.520996\n",
      "[73]\ttrain-mae:1090.265137\teval-mae:1150.577759\n",
      "[74]\ttrain-mae:1089.676147\teval-mae:1150.552368\n",
      "[75]\ttrain-mae:1089.223267\teval-mae:1150.442261\n",
      "[76]\ttrain-mae:1088.660278\teval-mae:1150.296509\n",
      "[77]\ttrain-mae:1087.484009\teval-mae:1150.129761\n",
      "[78]\ttrain-mae:1086.402588\teval-mae:1150.076782\n",
      "[79]\ttrain-mae:1085.530884\teval-mae:1149.947266\n",
      "[80]\ttrain-mae:1084.710205\teval-mae:1149.777344\n",
      "[81]\ttrain-mae:1084.165283\teval-mae:1149.653198\n",
      "[82]\ttrain-mae:1083.657837\teval-mae:1149.469971\n",
      "[83]\ttrain-mae:1082.726807\teval-mae:1149.418945\n",
      "[84]\ttrain-mae:1081.829346\teval-mae:1149.357544\n",
      "[85]\ttrain-mae:1080.686890\teval-mae:1149.121460\n",
      "[86]\ttrain-mae:1080.059692\teval-mae:1149.019165\n",
      "[87]\ttrain-mae:1079.471436\teval-mae:1148.859497\n",
      "[88]\ttrain-mae:1078.845215\teval-mae:1148.778809\n",
      "[89]\ttrain-mae:1077.982300\teval-mae:1148.767700\n",
      "[90]\ttrain-mae:1077.266113\teval-mae:1148.529175\n",
      "[91]\ttrain-mae:1076.407715\teval-mae:1148.400757\n",
      "[92]\ttrain-mae:1075.393555\teval-mae:1148.178711\n",
      "[93]\ttrain-mae:1074.555298\teval-mae:1148.031128\n",
      "[94]\ttrain-mae:1073.823364\teval-mae:1147.905640\n",
      "[95]\ttrain-mae:1073.021118\teval-mae:1147.728271\n",
      "[96]\ttrain-mae:1072.641602\teval-mae:1147.616699\n",
      "[97]\ttrain-mae:1071.646973\teval-mae:1147.368408\n",
      "[98]\ttrain-mae:1071.345947\teval-mae:1147.225342\n",
      "[99]\ttrain-mae:1070.607422\teval-mae:1146.945923\n",
      "[100]\ttrain-mae:1069.969482\teval-mae:1146.833008\n",
      "[101]\ttrain-mae:1069.420532\teval-mae:1146.666748\n",
      "[102]\ttrain-mae:1069.020752\teval-mae:1146.600464\n",
      "[103]\ttrain-mae:1068.393311\teval-mae:1146.548340\n",
      "[104]\ttrain-mae:1068.007812\teval-mae:1146.515137\n",
      "[105]\ttrain-mae:1066.812500\teval-mae:1146.430298\n",
      "[106]\ttrain-mae:1066.403931\teval-mae:1146.552368\n",
      "[107]\ttrain-mae:1066.057983\teval-mae:1146.556519\n",
      "[108]\ttrain-mae:1065.902710\teval-mae:1146.561646\n",
      "[109]\ttrain-mae:1065.220093\teval-mae:1146.548218\n",
      "[110]\ttrain-mae:1064.754883\teval-mae:1146.506348\n",
      "[111]\ttrain-mae:1064.444214\teval-mae:1146.470093\n",
      "[112]\ttrain-mae:1064.125732\teval-mae:1146.393066\n",
      "[113]\ttrain-mae:1063.720215\teval-mae:1146.350220\n",
      "[114]\ttrain-mae:1063.156494\teval-mae:1146.198730\n",
      "[115]\ttrain-mae:1062.764038\teval-mae:1146.105469\n",
      "[116]\ttrain-mae:1062.210693\teval-mae:1145.922241\n",
      "[117]\ttrain-mae:1061.873291\teval-mae:1145.846069\n",
      "[118]\ttrain-mae:1060.947754\teval-mae:1145.826904\n",
      "[119]\ttrain-mae:1060.172363\teval-mae:1145.370972\n",
      "[120]\ttrain-mae:1059.834106\teval-mae:1145.373657\n",
      "[121]\ttrain-mae:1058.950195\teval-mae:1145.225098\n",
      "[122]\ttrain-mae:1058.163452\teval-mae:1145.276855\n",
      "[123]\ttrain-mae:1057.448242\teval-mae:1145.308594\n",
      "[124]\ttrain-mae:1057.083374\teval-mae:1145.364380\n",
      "[125]\ttrain-mae:1056.677124\teval-mae:1145.381104\n",
      "[126]\ttrain-mae:1056.392700\teval-mae:1145.379761\n",
      "[127]\ttrain-mae:1055.990601\teval-mae:1145.232178\n",
      "[128]\ttrain-mae:1055.637695\teval-mae:1145.142334\n",
      "[129]\ttrain-mae:1055.202881\teval-mae:1145.047241\n",
      "[130]\ttrain-mae:1054.363892\teval-mae:1145.063599\n",
      "[131]\ttrain-mae:1054.015625\teval-mae:1145.089111\n",
      "[132]\ttrain-mae:1053.607910\teval-mae:1145.186279\n",
      "[133]\ttrain-mae:1053.467041\teval-mae:1145.128906\n",
      "[134]\ttrain-mae:1053.274048\teval-mae:1145.114868\n",
      "[135]\ttrain-mae:1052.927368\teval-mae:1145.149658\n",
      "[136]\ttrain-mae:1052.542480\teval-mae:1145.000732\n",
      "[137]\ttrain-mae:1051.704590\teval-mae:1144.960693\n",
      "[138]\ttrain-mae:1051.051147\teval-mae:1144.972290\n",
      "[139]\ttrain-mae:1050.401733\teval-mae:1144.762085\n",
      "[140]\ttrain-mae:1049.691406\teval-mae:1144.404663\n",
      "[141]\ttrain-mae:1048.955200\teval-mae:1144.196167\n",
      "[142]\ttrain-mae:1048.265503\teval-mae:1144.124634\n",
      "[143]\ttrain-mae:1047.892334\teval-mae:1144.047729\n",
      "[144]\ttrain-mae:1047.379883\teval-mae:1144.192261\n",
      "[145]\ttrain-mae:1046.914917\teval-mae:1144.039673\n",
      "[146]\ttrain-mae:1046.568726\teval-mae:1144.064941\n",
      "[147]\ttrain-mae:1046.341187\teval-mae:1144.092163\n",
      "[148]\ttrain-mae:1046.043457\teval-mae:1144.171875\n",
      "[149]\ttrain-mae:1045.444946\teval-mae:1144.432739\n",
      "[150]\ttrain-mae:1044.924438\teval-mae:1144.523926\n",
      "[151]\ttrain-mae:1044.207153\teval-mae:1144.509766\n",
      "[152]\ttrain-mae:1043.655884\teval-mae:1144.449951\n",
      "[153]\ttrain-mae:1042.902832\teval-mae:1144.412354\n",
      "[154]\ttrain-mae:1042.377319\teval-mae:1144.458252\n",
      "[155]\ttrain-mae:1041.860962\teval-mae:1144.355713\n",
      "[156]\ttrain-mae:1041.559326\teval-mae:1144.407227\n",
      "[157]\ttrain-mae:1041.086426\teval-mae:1144.379517\n",
      "[158]\ttrain-mae:1040.705200\teval-mae:1144.412109\n",
      "[159]\ttrain-mae:1040.560547\teval-mae:1144.490356\n",
      "[160]\ttrain-mae:1039.736328\teval-mae:1144.414673\n",
      "[161]\ttrain-mae:1039.002319\teval-mae:1144.309814\n",
      "[162]\ttrain-mae:1038.758179\teval-mae:1144.381592\n",
      "[163]\ttrain-mae:1038.343140\teval-mae:1144.382690\n",
      "[164]\ttrain-mae:1037.854248\teval-mae:1144.416382\n",
      "[165]\ttrain-mae:1037.065552\teval-mae:1144.591187\n",
      "[166]\ttrain-mae:1036.592407\teval-mae:1144.519531\n",
      "[167]\ttrain-mae:1035.894653\teval-mae:1144.645752\n",
      "[168]\ttrain-mae:1035.577759\teval-mae:1144.692871\n",
      "[169]\ttrain-mae:1035.065674\teval-mae:1144.601074\n",
      "[170]\ttrain-mae:1034.583496\teval-mae:1144.563354\n",
      "Stopping. Best iteration:\n",
      "[145]\ttrain-mae:1046.914917\teval-mae:1144.039673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if kfolds > 1:\n",
    "    kf = KFold(train.shape[0], n_folds=kfolds)\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        dtest = xgb.DMatrix(test[test.columns[1:]])\n",
    "        print('Fold {0}'.format(i + 1))\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        dtrain = xgb.DMatrix(X_train[X_train.columns[1:-1]],label=X_train.loss)\n",
    "        dvalid = xgb.DMatrix(X_val[X_val.columns[1:-1]],label=X_val.loss)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "        gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                            obj=logregobj,\n",
    "                            feval=xg_eval_mae,\n",
    "                            early_stopping_rounds=25)\n",
    "        del dtrain\n",
    "        del dvalid\n",
    "        gc.collect()\n",
    "        allpredictions['p'+str(i)] = gbdt.predict(dtest)\n",
    "        del dtest\n",
    "        del gbdt\n",
    "        gc.collect()\n",
    "else:\n",
    "    #dtest = xgb.DMatrix(test[test.columns[1:]].values)\n",
    "    dvalid = xgb.DMatrix(X_val,label = y_val)\n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                         obj=logregobj,\n",
    "                         feval=xg_eval_mae,\n",
    "                         early_stopping_rounds=25)\n",
    "    print mean_absolute_error(((np.exp(y_val))-200),(np.exp(gbdt.predict(dvalid))-200))\n",
    "    #allpredictions['p1'] = gbdt.predict(dtest)\n",
    "    del dtrain\n",
    "    del dtest\n",
    "    del gbdt\n",
    "    gc.collect()\n",
    "\n",
    "#print(allpredictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfolds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (150655,) (169486,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-761a4f3742e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                          \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogregobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                          \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxg_eval_mae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                          early_stopping_rounds=25)\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#allpredictions['p1'] = gbdt.predict(dtest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jenny\\Anaconda2\\lib\\site-packages\\xgboost-0.40-py2.7.egg\\xgboost.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, early_stopping_rounds, evals_result)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jenny\\Anaconda2\\lib\\site-packages\\xgboost-0.40-py2.7.egg\\xgboost.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, it, fobj)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-af719ebfab48>\u001b[0m in \u001b[0;36mlogregobj\u001b[1;34m(preds, dtrain)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (150655,) (169486,) "
     ]
    }
   ],
   "source": [
    "if kfolds > 1:\n",
    "    kf = KFold(train.shape[0], n_folds=kfolds)\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        dtest = xgb.DMatrix(test[test.columns[1:]])\n",
    "        print('Fold {0}'.format(i + 1))\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        dtrain = xgb.DMatrix(X_train[X_train.columns[1:-1]],label=X_train.loss)\n",
    "        dvalid = xgb.DMatrix(X_val[X_val.columns[1:-1]],label=X_val.loss)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "        gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                            obj=logregobj,\n",
    "                            feval=xg_eval_mae,\n",
    "                            early_stopping_rounds=25)\n",
    "        del dtrain\n",
    "        del dvalid\n",
    "        gc.collect()\n",
    "        allpredictions['p'+str(i)] = gbdt.predict(dtest)\n",
    "        del dtest\n",
    "        del gbdt\n",
    "        gc.collect()\n",
    "else:\n",
    "    #dtest = xgb.DMatrix(test[test.columns[1:]].values)\n",
    "    dvalid = xgb.DMatrix(X_val,label = y_val)\n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                         obj=logregobj,\n",
    "                         feval=xg_eval_mae,\n",
    "                         early_stopping_rounds=25)\n",
    "    print mean_absolute_error(((np.exp(y_val))-200),(np.exp(gbdt.predict(dvalid))-200))\n",
    "    #allpredictions['p1'] = gbdt.predict(dtest)\n",
    "    del dtrain\n",
    "    del dtest\n",
    "    del gbdt\n",
    "    gc.collect()\n",
    "\n",
    "#print(allpredictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.52739954,  7.81086779,  9.23377323, ...,  7.95283222,\n",
       "        7.24534369,  8.06972313], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125546"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbdt.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
