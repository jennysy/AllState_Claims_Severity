{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\hudsondata\\\\Machine Learning\\\\Kaggle\\\\AllState\\\\train.csv')\n",
    "dataset_test= pd.read_csv('C:\\\\hudsondata\\\\Machine Learning\\\\Kaggle\\\\AllState\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['loss'] = np.log1p(train['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = train.iloc[:,1:]\n",
    "dataset_test = dataset_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = dataset.columns\n",
    "labels = []\n",
    "for i in range(0, 116):\n",
    "    train = dataset[cols[i]].unique()\n",
    "    test = dataset_test[cols[i]].unique()\n",
    "    labels.append(list(set(train)|set(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats =[]\n",
    "for i in range(0, 116):\n",
    "    #Label Encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels[i])\n",
    "    feature = label_encoder.transform(dataset.iloc[:,i])\n",
    "    feature = feature.reshape(dataset.shape[0],1)\n",
    "    #One Hot Encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, n_values= len(labels[i]))\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    cats.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_cats = np.column_stack(cats)\n",
    "dataset_encoded = np.concatenate((encoded_cats, dataset.iloc[:,116:].values),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del cats\n",
    "del feature\n",
    "del dataset\n",
    "del encoded_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ohe.csv\", dataset_encoded, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r, c = dataset_encoded.shape\n",
    "X = dataset_encoded[:,0:(c-1)]\n",
    "Y = dataset_encoded[:,(c-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = 0.1\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=val_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,label=Y_train)\n",
    "dtest = xgb.DMatrix(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':9, 'eta':0.1, 'silent':1, 'objective':'reg:linear' }\n",
    "#param['nthread'] = 4\n",
    "param['eval_metric'] = 'rmse'\n",
    "param['subsample'] = 0.86\n",
    "param['colsample_bytree']= 0.92\n",
    "param['min_child_weight'] = 2\n",
    "param['booster'] = \"gbtree\"\n",
    "param['gamma'] = 0.1\n",
    "param['colsample_bylevel'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until X_train error hasn't decreased in 100 rounds.\n",
      "[0]\tX_train-rmse:6.513639\n",
      "[1]\tX_train-rmse:5.868634\n",
      "[2]\tX_train-rmse:5.288816\n",
      "[3]\tX_train-rmse:4.767547\n",
      "[4]\tX_train-rmse:4.299121\n",
      "[5]\tX_train-rmse:3.878295\n",
      "[6]\tX_train-rmse:3.500313\n",
      "[7]\tX_train-rmse:3.161030\n",
      "[8]\tX_train-rmse:2.856661\n",
      "[9]\tX_train-rmse:2.583763\n",
      "[10]\tX_train-rmse:2.339393\n",
      "[11]\tX_train-rmse:2.120476\n",
      "[12]\tX_train-rmse:1.924895\n",
      "[13]\tX_train-rmse:1.750365\n",
      "[14]\tX_train-rmse:1.594792\n",
      "[15]\tX_train-rmse:1.455861\n",
      "[16]\tX_train-rmse:1.333088\n",
      "[17]\tX_train-rmse:1.224472\n",
      "[18]\tX_train-rmse:1.128378\n",
      "[19]\tX_train-rmse:1.043853\n",
      "[20]\tX_train-rmse:0.969882\n",
      "[21]\tX_train-rmse:0.905239\n",
      "[22]\tX_train-rmse:0.848954\n",
      "[23]\tX_train-rmse:0.800177\n",
      "[24]\tX_train-rmse:0.758184\n",
      "[25]\tX_train-rmse:0.722292\n",
      "[26]\tX_train-rmse:0.691457\n",
      "[27]\tX_train-rmse:0.665149\n",
      "[28]\tX_train-rmse:0.642646\n",
      "[29]\tX_train-rmse:0.623456\n",
      "[30]\tX_train-rmse:0.607648\n",
      "[31]\tX_train-rmse:0.593949\n",
      "[32]\tX_train-rmse:0.582544\n",
      "[33]\tX_train-rmse:0.573090\n",
      "[34]\tX_train-rmse:0.564744\n",
      "[35]\tX_train-rmse:0.557867\n",
      "[36]\tX_train-rmse:0.551759\n",
      "[37]\tX_train-rmse:0.546793\n",
      "[38]\tX_train-rmse:0.542429\n",
      "[39]\tX_train-rmse:0.538853\n",
      "[40]\tX_train-rmse:0.535822\n",
      "[41]\tX_train-rmse:0.533247\n",
      "[42]\tX_train-rmse:0.531085\n",
      "[43]\tX_train-rmse:0.529005\n",
      "[44]\tX_train-rmse:0.527029\n",
      "[45]\tX_train-rmse:0.525481\n",
      "[46]\tX_train-rmse:0.523995\n",
      "[47]\tX_train-rmse:0.522938\n",
      "[48]\tX_train-rmse:0.521717\n",
      "[49]\tX_train-rmse:0.520767\n",
      "[50]\tX_train-rmse:0.519988\n",
      "[51]\tX_train-rmse:0.519073\n",
      "[52]\tX_train-rmse:0.518050\n",
      "[53]\tX_train-rmse:0.516926\n",
      "[54]\tX_train-rmse:0.516150\n",
      "[55]\tX_train-rmse:0.515447\n",
      "[56]\tX_train-rmse:0.514613\n",
      "[57]\tX_train-rmse:0.514069\n",
      "[58]\tX_train-rmse:0.513222\n",
      "[59]\tX_train-rmse:0.512534\n",
      "[60]\tX_train-rmse:0.511893\n",
      "[61]\tX_train-rmse:0.511121\n",
      "[62]\tX_train-rmse:0.510584\n",
      "[63]\tX_train-rmse:0.510129\n",
      "[64]\tX_train-rmse:0.509552\n",
      "[65]\tX_train-rmse:0.508995\n",
      "[66]\tX_train-rmse:0.508459\n",
      "[67]\tX_train-rmse:0.507881\n",
      "[68]\tX_train-rmse:0.507367\n",
      "[69]\tX_train-rmse:0.506909\n",
      "[70]\tX_train-rmse:0.506478\n",
      "[71]\tX_train-rmse:0.506069\n",
      "[72]\tX_train-rmse:0.505507\n",
      "[73]\tX_train-rmse:0.505015\n",
      "[74]\tX_train-rmse:0.504710\n",
      "[75]\tX_train-rmse:0.504218\n",
      "[76]\tX_train-rmse:0.503734\n",
      "[77]\tX_train-rmse:0.503399\n",
      "[78]\tX_train-rmse:0.502911\n",
      "[79]\tX_train-rmse:0.502514\n",
      "[80]\tX_train-rmse:0.501965\n",
      "[81]\tX_train-rmse:0.501686\n",
      "[82]\tX_train-rmse:0.501256\n",
      "[83]\tX_train-rmse:0.500992\n",
      "[84]\tX_train-rmse:0.500656\n",
      "[85]\tX_train-rmse:0.500375\n",
      "[86]\tX_train-rmse:0.499952\n",
      "[87]\tX_train-rmse:0.499493\n",
      "[88]\tX_train-rmse:0.499098\n",
      "[89]\tX_train-rmse:0.498693\n",
      "[90]\tX_train-rmse:0.498319\n",
      "[91]\tX_train-rmse:0.497743\n",
      "[92]\tX_train-rmse:0.497467\n",
      "[93]\tX_train-rmse:0.497184\n",
      "[94]\tX_train-rmse:0.496889\n",
      "[95]\tX_train-rmse:0.496535\n",
      "[96]\tX_train-rmse:0.496172\n",
      "[97]\tX_train-rmse:0.495955\n",
      "[98]\tX_train-rmse:0.495691\n",
      "[99]\tX_train-rmse:0.495255\n",
      "[100]\tX_train-rmse:0.494781\n",
      "[101]\tX_train-rmse:0.494668\n",
      "[102]\tX_train-rmse:0.494371\n",
      "[103]\tX_train-rmse:0.494211\n",
      "[104]\tX_train-rmse:0.493952\n",
      "[105]\tX_train-rmse:0.493660\n",
      "[106]\tX_train-rmse:0.493263\n",
      "[107]\tX_train-rmse:0.493007\n",
      "[108]\tX_train-rmse:0.492628\n",
      "[109]\tX_train-rmse:0.492427\n",
      "[110]\tX_train-rmse:0.492148\n",
      "[111]\tX_train-rmse:0.492014\n",
      "[112]\tX_train-rmse:0.491521\n",
      "[113]\tX_train-rmse:0.491319\n",
      "[114]\tX_train-rmse:0.490996\n",
      "[115]\tX_train-rmse:0.490611\n",
      "[116]\tX_train-rmse:0.490290\n",
      "[117]\tX_train-rmse:0.490022\n",
      "[118]\tX_train-rmse:0.489706\n",
      "[119]\tX_train-rmse:0.489391\n",
      "[120]\tX_train-rmse:0.489017\n",
      "[121]\tX_train-rmse:0.488749\n",
      "[122]\tX_train-rmse:0.488566\n",
      "[123]\tX_train-rmse:0.488238\n",
      "[124]\tX_train-rmse:0.488044\n",
      "[125]\tX_train-rmse:0.487825\n",
      "[126]\tX_train-rmse:0.487499\n",
      "[127]\tX_train-rmse:0.487147\n",
      "[128]\tX_train-rmse:0.486863\n",
      "[129]\tX_train-rmse:0.486594\n",
      "[130]\tX_train-rmse:0.486315\n",
      "[131]\tX_train-rmse:0.486043\n",
      "[132]\tX_train-rmse:0.485666\n",
      "[133]\tX_train-rmse:0.485475\n",
      "[134]\tX_train-rmse:0.485220\n",
      "[135]\tX_train-rmse:0.485058\n",
      "[136]\tX_train-rmse:0.484738\n",
      "[137]\tX_train-rmse:0.484601\n",
      "[138]\tX_train-rmse:0.484367\n",
      "[139]\tX_train-rmse:0.483948\n",
      "[140]\tX_train-rmse:0.483738\n",
      "[141]\tX_train-rmse:0.483417\n",
      "[142]\tX_train-rmse:0.483143\n",
      "[143]\tX_train-rmse:0.482864\n",
      "[144]\tX_train-rmse:0.482637\n",
      "[145]\tX_train-rmse:0.482387\n",
      "[146]\tX_train-rmse:0.482246\n",
      "[147]\tX_train-rmse:0.482031\n",
      "[148]\tX_train-rmse:0.481859\n",
      "[149]\tX_train-rmse:0.481661\n",
      "[150]\tX_train-rmse:0.481483\n",
      "[151]\tX_train-rmse:0.481327\n",
      "[152]\tX_train-rmse:0.481145\n",
      "[153]\tX_train-rmse:0.480889\n",
      "[154]\tX_train-rmse:0.480674\n",
      "[155]\tX_train-rmse:0.480429\n",
      "[156]\tX_train-rmse:0.480277\n",
      "[157]\tX_train-rmse:0.480090\n",
      "[158]\tX_train-rmse:0.480001\n",
      "[159]\tX_train-rmse:0.479821\n",
      "[160]\tX_train-rmse:0.479572\n",
      "[161]\tX_train-rmse:0.479513\n",
      "[162]\tX_train-rmse:0.479275\n",
      "[163]\tX_train-rmse:0.478997\n",
      "[164]\tX_train-rmse:0.478710\n",
      "[165]\tX_train-rmse:0.478508\n",
      "[166]\tX_train-rmse:0.478336\n",
      "[167]\tX_train-rmse:0.478125\n",
      "[168]\tX_train-rmse:0.477822\n",
      "[169]\tX_train-rmse:0.477627\n",
      "[170]\tX_train-rmse:0.477480\n",
      "[171]\tX_train-rmse:0.477268\n",
      "[172]\tX_train-rmse:0.477009\n",
      "[173]\tX_train-rmse:0.476779\n",
      "[174]\tX_train-rmse:0.476595\n",
      "[175]\tX_train-rmse:0.476445\n",
      "[176]\tX_train-rmse:0.476235\n",
      "[177]\tX_train-rmse:0.476112\n",
      "[178]\tX_train-rmse:0.475948\n",
      "[179]\tX_train-rmse:0.475710\n",
      "[180]\tX_train-rmse:0.475587\n",
      "[181]\tX_train-rmse:0.475189\n",
      "[182]\tX_train-rmse:0.475002\n",
      "[183]\tX_train-rmse:0.474797\n",
      "[184]\tX_train-rmse:0.474483\n",
      "[185]\tX_train-rmse:0.474331\n",
      "[186]\tX_train-rmse:0.473966\n",
      "[187]\tX_train-rmse:0.473858\n",
      "[188]\tX_train-rmse:0.473450\n",
      "[189]\tX_train-rmse:0.473251\n",
      "[190]\tX_train-rmse:0.473159\n",
      "[191]\tX_train-rmse:0.472996\n",
      "[192]\tX_train-rmse:0.472856\n",
      "[193]\tX_train-rmse:0.472551\n",
      "[194]\tX_train-rmse:0.472254\n",
      "[195]\tX_train-rmse:0.472047\n",
      "[196]\tX_train-rmse:0.471653\n",
      "[197]\tX_train-rmse:0.471367\n",
      "[198]\tX_train-rmse:0.471056\n",
      "[199]\tX_train-rmse:0.470845\n",
      "[200]\tX_train-rmse:0.470724\n",
      "[201]\tX_train-rmse:0.470609\n",
      "[202]\tX_train-rmse:0.470468\n",
      "[203]\tX_train-rmse:0.470265\n",
      "[204]\tX_train-rmse:0.470017\n",
      "[205]\tX_train-rmse:0.469866\n",
      "[206]\tX_train-rmse:0.469681\n",
      "[207]\tX_train-rmse:0.469470\n",
      "[208]\tX_train-rmse:0.469265\n",
      "[209]\tX_train-rmse:0.469061\n",
      "[210]\tX_train-rmse:0.468784\n",
      "[211]\tX_train-rmse:0.468569\n",
      "[212]\tX_train-rmse:0.468394\n",
      "[213]\tX_train-rmse:0.468327\n",
      "[214]\tX_train-rmse:0.468005\n",
      "[215]\tX_train-rmse:0.467940\n",
      "[216]\tX_train-rmse:0.467759\n",
      "[217]\tX_train-rmse:0.467560\n",
      "[218]\tX_train-rmse:0.467228\n",
      "[219]\tX_train-rmse:0.467048\n",
      "[220]\tX_train-rmse:0.466916\n",
      "[221]\tX_train-rmse:0.466835\n",
      "[222]\tX_train-rmse:0.466798\n",
      "[223]\tX_train-rmse:0.466563\n",
      "[224]\tX_train-rmse:0.466296\n",
      "[225]\tX_train-rmse:0.466161\n",
      "[226]\tX_train-rmse:0.465872\n",
      "[227]\tX_train-rmse:0.465602\n",
      "[228]\tX_train-rmse:0.465533\n",
      "[229]\tX_train-rmse:0.465416\n",
      "[230]\tX_train-rmse:0.465276\n",
      "[231]\tX_train-rmse:0.465176\n",
      "[232]\tX_train-rmse:0.464881\n",
      "[233]\tX_train-rmse:0.464580\n",
      "[234]\tX_train-rmse:0.464527\n",
      "[235]\tX_train-rmse:0.464477\n",
      "[236]\tX_train-rmse:0.464419\n",
      "[237]\tX_train-rmse:0.464293\n",
      "[238]\tX_train-rmse:0.464145\n",
      "[239]\tX_train-rmse:0.464029\n",
      "[240]\tX_train-rmse:0.463907\n",
      "[241]\tX_train-rmse:0.463739\n",
      "[242]\tX_train-rmse:0.463576\n",
      "[243]\tX_train-rmse:0.463449\n",
      "[244]\tX_train-rmse:0.463306\n",
      "[245]\tX_train-rmse:0.463050\n",
      "[246]\tX_train-rmse:0.462838\n",
      "[247]\tX_train-rmse:0.462673\n",
      "[248]\tX_train-rmse:0.462638\n",
      "[249]\tX_train-rmse:0.462563\n",
      "[250]\tX_train-rmse:0.462235\n",
      "[251]\tX_train-rmse:0.462076\n",
      "[252]\tX_train-rmse:0.461953\n",
      "[253]\tX_train-rmse:0.461716\n",
      "[254]\tX_train-rmse:0.461483\n",
      "[255]\tX_train-rmse:0.461276\n",
      "[256]\tX_train-rmse:0.461128\n",
      "[257]\tX_train-rmse:0.460793\n",
      "[258]\tX_train-rmse:0.460384\n",
      "[259]\tX_train-rmse:0.460277\n",
      "[260]\tX_train-rmse:0.460173\n",
      "[261]\tX_train-rmse:0.459961\n",
      "[262]\tX_train-rmse:0.459794\n",
      "[263]\tX_train-rmse:0.459591\n",
      "[264]\tX_train-rmse:0.459441\n",
      "[265]\tX_train-rmse:0.459207\n",
      "[266]\tX_train-rmse:0.458938\n",
      "[267]\tX_train-rmse:0.458772\n",
      "[268]\tX_train-rmse:0.458539\n",
      "[269]\tX_train-rmse:0.458277\n",
      "[270]\tX_train-rmse:0.458076\n",
      "[271]\tX_train-rmse:0.457919\n",
      "[272]\tX_train-rmse:0.457788\n",
      "[273]\tX_train-rmse:0.457558\n",
      "[274]\tX_train-rmse:0.457468\n",
      "[275]\tX_train-rmse:0.457203\n",
      "[276]\tX_train-rmse:0.457005\n",
      "[277]\tX_train-rmse:0.456826\n",
      "[278]\tX_train-rmse:0.456682\n",
      "[279]\tX_train-rmse:0.456591\n",
      "[280]\tX_train-rmse:0.456512\n",
      "[281]\tX_train-rmse:0.456437\n",
      "[282]\tX_train-rmse:0.456216\n",
      "[283]\tX_train-rmse:0.455849\n",
      "[284]\tX_train-rmse:0.455767\n",
      "[285]\tX_train-rmse:0.455691\n",
      "[286]\tX_train-rmse:0.455643\n",
      "[287]\tX_train-rmse:0.455451\n",
      "[288]\tX_train-rmse:0.455331\n",
      "[289]\tX_train-rmse:0.455218\n",
      "[290]\tX_train-rmse:0.454886\n",
      "[291]\tX_train-rmse:0.454731\n",
      "[292]\tX_train-rmse:0.454673\n",
      "[293]\tX_train-rmse:0.454605\n",
      "[294]\tX_train-rmse:0.454219\n",
      "[295]\tX_train-rmse:0.453991\n",
      "[296]\tX_train-rmse:0.453717\n",
      "[297]\tX_train-rmse:0.453545\n",
      "[298]\tX_train-rmse:0.453450\n",
      "[299]\tX_train-rmse:0.453117\n",
      "[300]\tX_train-rmse:0.452962\n",
      "[301]\tX_train-rmse:0.452756\n",
      "[302]\tX_train-rmse:0.452606\n",
      "[303]\tX_train-rmse:0.452521\n",
      "[304]\tX_train-rmse:0.452196\n",
      "[305]\tX_train-rmse:0.452053\n",
      "[306]\tX_train-rmse:0.451888\n",
      "[307]\tX_train-rmse:0.451745\n",
      "[308]\tX_train-rmse:0.451659\n",
      "[309]\tX_train-rmse:0.451511\n",
      "[310]\tX_train-rmse:0.451321\n",
      "[311]\tX_train-rmse:0.451256\n",
      "[312]\tX_train-rmse:0.451100\n",
      "[313]\tX_train-rmse:0.450823\n",
      "[314]\tX_train-rmse:0.450662\n",
      "[315]\tX_train-rmse:0.450584\n",
      "[316]\tX_train-rmse:0.450432\n",
      "[317]\tX_train-rmse:0.450188\n",
      "[318]\tX_train-rmse:0.450047\n",
      "[319]\tX_train-rmse:0.449924\n",
      "[320]\tX_train-rmse:0.449765\n",
      "[321]\tX_train-rmse:0.449700\n",
      "[322]\tX_train-rmse:0.449561\n",
      "[323]\tX_train-rmse:0.449479\n",
      "[324]\tX_train-rmse:0.449263\n",
      "[325]\tX_train-rmse:0.449029\n",
      "[326]\tX_train-rmse:0.448950\n",
      "[327]\tX_train-rmse:0.448706\n",
      "[328]\tX_train-rmse:0.448510\n",
      "[329]\tX_train-rmse:0.448262\n",
      "[330]\tX_train-rmse:0.448210\n",
      "[331]\tX_train-rmse:0.448119\n",
      "[332]\tX_train-rmse:0.447977\n",
      "[333]\tX_train-rmse:0.447866\n",
      "[334]\tX_train-rmse:0.447627\n",
      "[335]\tX_train-rmse:0.447474\n",
      "[336]\tX_train-rmse:0.447232\n",
      "[337]\tX_train-rmse:0.447070\n",
      "[338]\tX_train-rmse:0.446853\n",
      "[339]\tX_train-rmse:0.446654\n",
      "[340]\tX_train-rmse:0.446601\n",
      "[341]\tX_train-rmse:0.446347\n",
      "[342]\tX_train-rmse:0.446134\n",
      "[343]\tX_train-rmse:0.445980\n",
      "[344]\tX_train-rmse:0.445783\n",
      "[345]\tX_train-rmse:0.445695\n",
      "[346]\tX_train-rmse:0.445477\n",
      "[347]\tX_train-rmse:0.445431\n",
      "[348]\tX_train-rmse:0.445359\n",
      "[349]\tX_train-rmse:0.445205\n",
      "[350]\tX_train-rmse:0.445168\n",
      "[351]\tX_train-rmse:0.444924\n",
      "[352]\tX_train-rmse:0.444774\n",
      "[353]\tX_train-rmse:0.444492\n",
      "[354]\tX_train-rmse:0.444334\n",
      "[355]\tX_train-rmse:0.444193\n",
      "[356]\tX_train-rmse:0.444136\n",
      "[357]\tX_train-rmse:0.443932\n",
      "[358]\tX_train-rmse:0.443631\n",
      "[359]\tX_train-rmse:0.443493\n",
      "[360]\tX_train-rmse:0.443341\n",
      "[361]\tX_train-rmse:0.443090\n",
      "[362]\tX_train-rmse:0.442933\n",
      "[363]\tX_train-rmse:0.442859\n",
      "[364]\tX_train-rmse:0.442711\n",
      "[365]\tX_train-rmse:0.442651\n",
      "[366]\tX_train-rmse:0.442410\n",
      "[367]\tX_train-rmse:0.442314\n",
      "[368]\tX_train-rmse:0.442223\n",
      "[369]\tX_train-rmse:0.442094\n",
      "[370]\tX_train-rmse:0.442004\n",
      "[371]\tX_train-rmse:0.441872\n",
      "[372]\tX_train-rmse:0.441734\n",
      "[373]\tX_train-rmse:0.441520\n",
      "[374]\tX_train-rmse:0.441447\n",
      "[375]\tX_train-rmse:0.441123\n",
      "[376]\tX_train-rmse:0.440957\n",
      "[377]\tX_train-rmse:0.440756\n",
      "[378]\tX_train-rmse:0.440516\n",
      "[379]\tX_train-rmse:0.440251\n",
      "[380]\tX_train-rmse:0.440141\n",
      "[381]\tX_train-rmse:0.440100\n",
      "[382]\tX_train-rmse:0.439904\n",
      "[383]\tX_train-rmse:0.439779\n",
      "[384]\tX_train-rmse:0.439598\n",
      "[385]\tX_train-rmse:0.439509\n",
      "[386]\tX_train-rmse:0.439388\n",
      "[387]\tX_train-rmse:0.439231\n",
      "[388]\tX_train-rmse:0.439029\n",
      "[389]\tX_train-rmse:0.438925\n",
      "[390]\tX_train-rmse:0.438744\n",
      "[391]\tX_train-rmse:0.438521\n",
      "[392]\tX_train-rmse:0.438420\n",
      "[393]\tX_train-rmse:0.438266\n",
      "[394]\tX_train-rmse:0.438063\n",
      "[395]\tX_train-rmse:0.437916\n",
      "[396]\tX_train-rmse:0.437709\n",
      "[397]\tX_train-rmse:0.437701\n",
      "[398]\tX_train-rmse:0.437615\n",
      "[399]\tX_train-rmse:0.437479\n",
      "[400]\tX_train-rmse:0.437297\n",
      "[401]\tX_train-rmse:0.437066\n",
      "[402]\tX_train-rmse:0.436929\n",
      "[403]\tX_train-rmse:0.436717\n",
      "[404]\tX_train-rmse:0.436480\n",
      "[405]\tX_train-rmse:0.436326\n",
      "[406]\tX_train-rmse:0.436091\n",
      "[407]\tX_train-rmse:0.435928\n",
      "[408]\tX_train-rmse:0.435703\n",
      "[409]\tX_train-rmse:0.435623\n",
      "[410]\tX_train-rmse:0.435496\n",
      "[411]\tX_train-rmse:0.435355\n",
      "[412]\tX_train-rmse:0.435285\n",
      "[413]\tX_train-rmse:0.434996\n",
      "[414]\tX_train-rmse:0.434782\n",
      "[415]\tX_train-rmse:0.434539\n",
      "[416]\tX_train-rmse:0.434362\n",
      "[417]\tX_train-rmse:0.434213\n",
      "[418]\tX_train-rmse:0.434044\n",
      "[419]\tX_train-rmse:0.433962\n",
      "[420]\tX_train-rmse:0.433756\n",
      "[421]\tX_train-rmse:0.433625\n",
      "[422]\tX_train-rmse:0.433440\n",
      "[423]\tX_train-rmse:0.433337\n",
      "[424]\tX_train-rmse:0.433191\n",
      "[425]\tX_train-rmse:0.432974\n",
      "[426]\tX_train-rmse:0.432726\n",
      "[427]\tX_train-rmse:0.432499\n",
      "[428]\tX_train-rmse:0.432293\n",
      "[429]\tX_train-rmse:0.432110\n",
      "[430]\tX_train-rmse:0.432073\n",
      "[431]\tX_train-rmse:0.431975\n",
      "[432]\tX_train-rmse:0.431918\n",
      "[433]\tX_train-rmse:0.431793\n",
      "[434]\tX_train-rmse:0.431606\n",
      "[435]\tX_train-rmse:0.431431\n",
      "[436]\tX_train-rmse:0.431290\n",
      "[437]\tX_train-rmse:0.431229\n",
      "[438]\tX_train-rmse:0.431041\n",
      "[439]\tX_train-rmse:0.430879\n",
      "[440]\tX_train-rmse:0.430784\n",
      "[441]\tX_train-rmse:0.430679\n",
      "[442]\tX_train-rmse:0.430437\n",
      "[443]\tX_train-rmse:0.430179\n",
      "[444]\tX_train-rmse:0.429948\n",
      "[445]\tX_train-rmse:0.429747\n",
      "[446]\tX_train-rmse:0.429568\n",
      "[447]\tX_train-rmse:0.429362\n",
      "[448]\tX_train-rmse:0.429203\n",
      "[449]\tX_train-rmse:0.429098\n",
      "[450]\tX_train-rmse:0.428889\n",
      "[451]\tX_train-rmse:0.428765\n",
      "[452]\tX_train-rmse:0.428668\n",
      "[453]\tX_train-rmse:0.428449\n",
      "[454]\tX_train-rmse:0.428293\n",
      "[455]\tX_train-rmse:0.428025\n",
      "[456]\tX_train-rmse:0.427938\n",
      "[457]\tX_train-rmse:0.427780\n",
      "[458]\tX_train-rmse:0.427465\n",
      "[459]\tX_train-rmse:0.427345\n",
      "[460]\tX_train-rmse:0.427089\n",
      "[461]\tX_train-rmse:0.426870\n",
      "[462]\tX_train-rmse:0.426716\n",
      "[463]\tX_train-rmse:0.426634\n",
      "[464]\tX_train-rmse:0.426420\n",
      "[465]\tX_train-rmse:0.426289\n",
      "[466]\tX_train-rmse:0.426200\n",
      "[467]\tX_train-rmse:0.426051\n",
      "[468]\tX_train-rmse:0.425995\n",
      "[469]\tX_train-rmse:0.425874\n",
      "[470]\tX_train-rmse:0.425692\n",
      "[471]\tX_train-rmse:0.425653\n",
      "[472]\tX_train-rmse:0.425512\n",
      "[473]\tX_train-rmse:0.425404\n",
      "[474]\tX_train-rmse:0.425198\n",
      "[475]\tX_train-rmse:0.425034\n",
      "[476]\tX_train-rmse:0.424870\n",
      "[477]\tX_train-rmse:0.424608\n",
      "[478]\tX_train-rmse:0.424466\n",
      "[479]\tX_train-rmse:0.424262\n",
      "[480]\tX_train-rmse:0.424184\n",
      "[481]\tX_train-rmse:0.424128\n",
      "[482]\tX_train-rmse:0.423923\n",
      "[483]\tX_train-rmse:0.423711\n",
      "[484]\tX_train-rmse:0.423553\n",
      "[485]\tX_train-rmse:0.423460\n",
      "[486]\tX_train-rmse:0.423402\n",
      "[487]\tX_train-rmse:0.423134\n",
      "[488]\tX_train-rmse:0.423088\n",
      "[489]\tX_train-rmse:0.422982\n",
      "[490]\tX_train-rmse:0.422848\n",
      "[491]\tX_train-rmse:0.422756\n",
      "[492]\tX_train-rmse:0.422667\n",
      "[493]\tX_train-rmse:0.422573\n",
      "[494]\tX_train-rmse:0.422286\n",
      "[495]\tX_train-rmse:0.422117\n",
      "[496]\tX_train-rmse:0.422048\n",
      "[497]\tX_train-rmse:0.421947\n",
      "[498]\tX_train-rmse:0.421858\n",
      "[499]\tX_train-rmse:0.421661\n"
     ]
    }
   ],
   "source": [
    "watchlist  = [(dtrain,'X_train')]\n",
    "num_round = 500\n",
    "early_stopping_rounds=100\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158.5510165486946"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.expm1(Y_val), np.expm1(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
